{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (0.15.7)\n",
      "Requirement already satisfied: chardet in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: nltk in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: tabulate in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: emoji in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (2.12.1)\n",
      "Requirement already satisfied: dataclasses-json in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (2024.4.27)\n",
      "Requirement already satisfied: langdetect in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (3.9.6)\n",
      "Requirement already satisfied: backoff in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (0.25.5)\n",
      "Requirement already satisfied: wrapt in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (4.66.5)\n",
      "Requirement already satisfied: psutil in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured) (6.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from nltk->unstructured) (2024.7.24)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests->unstructured) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests->unstructured) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests->unstructured) (2024.7.4)\n",
      "Requirement already satisfied: deepdiff>=6.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (7.0.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (0.27.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (24.1)\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (4.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from deepdiff>=6.0->unstructured-client->unstructured) (4.1.0)\n",
      "Requirement already satisfied: anyio in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (0.2.14)\n",
      "Requirement already satisfied: lxml in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (5.3.0)\n",
      "Requirement already satisfied: unstructured[all-docs] in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (0.15.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (3.10.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (0.2.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (0.1.99)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: chardet in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (5.2.0)\n",
      "Requirement already satisfied: filetype in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.4.27)\n",
      "Requirement already satisfied: nltk in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (3.9.1)\n",
      "Requirement already satisfied: tabulate in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (4.12.3)\n",
      "Requirement already satisfied: emoji in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (2.12.1)\n",
      "Requirement already satisfied: dataclasses-json in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (2024.4.27)\n",
      "Requirement already satisfied: langdetect in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (3.9.6)\n",
      "Requirement already satisfied: backoff in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.25.5)\n",
      "Requirement already satisfied: wrapt in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (4.66.5)\n",
      "Requirement already satisfied: psutil in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (6.0.0)\n",
      "Requirement already satisfied: pdfminer.six in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (20231228)\n",
      "Requirement already satisfied: pikepdf in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (9.2.0)\n",
      "Requirement already satisfied: python-pptx>=1.0.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (1.0.2)\n",
      "Requirement already satisfied: onnx in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (1.16.2)\n",
      "Requirement already satisfied: networkx in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (3.3)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.3.13)\n",
      "Requirement already satisfied: markdown in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (3.7)\n",
      "Requirement already satisfied: xlrd in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: python-docx>=1.1.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (1.1.2)\n",
      "Requirement already satisfied: pdf2image in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: pypdf in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (4.3.1)\n",
      "Requirement already satisfied: google-cloud-vision in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (3.7.4)\n",
      "Requirement already satisfied: effdet in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: openpyxl in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (3.1.5)\n",
      "Requirement already satisfied: pillow-heif in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.18.0)\n",
      "Requirement already satisfied: pandas in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (2.2.2)\n",
      "Requirement already satisfied: pypandoc in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (1.13)\n",
      "Requirement already satisfied: python-oxmsg in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.0.1)\n",
      "Requirement already satisfied: unstructured-inference==0.7.36 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured[all-docs]) (0.7.36)\n",
      "Requirement already satisfied: layoutparser in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.3.4)\n",
      "Requirement already satisfied: python-multipart in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.0.9)\n",
      "Requirement already satisfied: huggingface-hub in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.24.5)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (4.10.0.84)\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (1.19.0)\n",
      "Requirement already satisfied: matplotlib in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (3.9.2)\n",
      "Requirement already satisfied: torch in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (2.2.2)\n",
      "Requirement already satisfied: timm in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (1.0.9)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (4.44.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (10.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from beautifulsoup4->unstructured[all-docs]) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from dataclasses-json->unstructured[all-docs]) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from dataclasses-json->unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: torchvision in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from effdet->unstructured[all-docs]) (0.17.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from effdet->unstructured[all-docs]) (2.0.8)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from effdet->unstructured[all-docs]) (2.3.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (2.19.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-vision->unstructured[all-docs]) (2.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-vision->unstructured[all-docs]) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-vision->unstructured[all-docs]) (4.25.4)\n",
      "Requirement already satisfied: six in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langdetect->unstructured[all-docs]) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from nltk->unstructured[all-docs]) (2024.7.24)\n",
      "Requirement already satisfied: et-xmlfile in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from openpyxl->unstructured[all-docs]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pdfminer.six->unstructured[all-docs]) (43.0.0)\n",
      "Requirement already satisfied: Deprecated in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pikepdf->unstructured[all-docs]) (1.2.14)\n",
      "Requirement already satisfied: olefile in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from python-oxmsg->unstructured[all-docs]) (0.47)\n",
      "Requirement already satisfied: deepdiff>=6.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured[all-docs]) (7.0.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured[all-docs]) (0.27.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured[all-docs]) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured[all-docs]) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured[all-docs]) (1.6.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from unstructured-client->unstructured[all-docs]) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from deepdiff>=6.0->unstructured-client->unstructured[all-docs]) (4.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.63.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.65.5)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (4.9)\n",
      "Requirement already satisfied: anyio in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: coloredlogs in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (24.3.25)\n",
      "Requirement already satisfied: sympy in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (1.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (3.1.2)\n",
      "Requirement already satisfied: safetensors in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from timm->unstructured-inference==0.7.36->unstructured[all-docs]) (0.4.4)\n",
      "Requirement already satisfied: filelock in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (3.15.4)\n",
      "Requirement already satisfied: jinja2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (2024.6.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[all-docs]) (0.19.1)\n",
      "Requirement already satisfied: scipy in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (1.14.1)\n",
      "Requirement already satisfied: iopath in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (0.11.4)\n",
      "Requirement already satisfied: pycparser in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.22)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.6.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (1.2.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (10.0)\n",
      "Requirement already satisfied: portalocker in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (2.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured[all-docs]) (2.1.5)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (4.30.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain unstructured[all-docs] lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install certifi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ssl\n",
      "  Using cached ssl-1.16.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[19 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/pip-build-env-hiqxj_6v/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 332, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/pip-build-env-hiqxj_6v/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 302, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/pip-build-env-hiqxj_6v/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 503, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/pip-build-env-hiqxj_6v/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 318, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 33\n",
      "  \u001b[31m   \u001b[0m     print 'looking for', f\n",
      "  \u001b[31m   \u001b[0m     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m SyntaxError: Missing parentheses in call to 'print'. Did you mean print(...)?\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/pip-req-build-up911tjn\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/pip-req-build-up911tjn\n",
      "  Resolved https://github.com/openai/whisper.git to commit 279133e3107392276dc509148da1f41bfb532c7e\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from openai-whisper==20231117) (0.60.0)\n",
      "Requirement already satisfied: numpy in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.4)\n",
      "Requirement already satisfied: torch in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from openai-whisper==20231117) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.5)\n",
      "Requirement already satisfied: more-itertools in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from openai-whisper==20231117) (10.4.0)\n",
      "Requirement already satisfied: tiktoken in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from openai-whisper==20231117) (0.3.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n",
      "Requirement already satisfied: filelock in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_community in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (3.10.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (0.2.14)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (0.2.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (0.1.99)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (0.2.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (3.10.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (0.2.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (0.1.99)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ffmpeg in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ssl\n",
    "%pip install git+https://github.com/openai/whisper.git \n",
    "%pip install langchain_community\n",
    "%pip install langchain\n",
    "%pip install ffmpeg\n",
    "\n",
    "#brew install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "built with Apple clang version 14.0.0 (clang-1400.0.29.202)\n",
      "configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "libavutil      59.  8.100 / 59.  8.100\n",
      "libavcodec     61.  3.100 / 61.  3.100\n",
      "libavformat    61.  1.100 / 61.  1.100\n",
      "libavdevice    61.  1.100 / 61.  1.100\n",
      "libavfilter    10.  1.100 / 10.  1.100\n",
      "libswscale      8.  1.100 /  8.  1.100\n",
      "libswresample   5.  1.100 /  5.  1.100\n",
      "libpostproc    58.  1.100 / 58.  1.100\n",
      "FFmpeg is accessible.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PATH'] += ':/usr/local/bin' \n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    subprocess.run([\"ffmpeg\", \"-version\"], check=True)\n",
    "    print(\"FFmpeg is accessible.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"FFmpeg is not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import whisper\n",
    "import os\n",
    "import tempfile\n",
    "import uuid\n",
    "import requests\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import TextLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio_text_chunks\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Call the function with your directory path\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m audio_docs \u001b[38;5;241m=\u001b[39m \u001b[43mgenenerate_audio_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m, in \u001b[0;36mgenenerate_audio_docs\u001b[0;34m(audio_dir)\u001b[0m\n\u001b[1;32m     20\u001b[0m splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Iterate over files in the specified directory\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_dir\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(filename)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# Full path to the audio file\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio'"
     ]
    }
   ],
   "source": [
    "# model = whisper.load_model(\"base\")\n",
    "# result = model.transcribe(\"NN-audio.mp3\")\n",
    "# print(result)\n",
    "# with open(\"transcription.pdf\",\"w\") as f:\n",
    "#   f.write(result[\"text\"])\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import whisper\n",
    "import os\n",
    "\n",
    "def genenerate_audio_docs(audio_dir):\n",
    "    audio_text_chunks = []\n",
    "\n",
    "    # Load the Whisper model\n",
    "    model = whisper.load_model(\"base\")\n",
    "    \n",
    "    # Initialize the text splitter\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "    # Iterate over files in the specified directory\n",
    "    for filename in sorted(os.listdir(audio_dir)):\n",
    "        print(filename)\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            # Full path to the audio file\n",
    "            audio_path = os.path.join(audio_dir, filename)\n",
    "            \n",
    "            # Transcribe the audio file\n",
    "            result = model.transcribe(audio_path)\n",
    "            \n",
    "            # The transcription text is in result['text']\n",
    "            transcription_text = result['text']\n",
    "            \n",
    "            # Create a document object from the transcription text\n",
    "            doc = Document(page_content=transcription_text,metadata={})\n",
    "            \n",
    "            # Split the document into smaller chunks\n",
    "            texts = splitter.split_documents([doc])\n",
    "            \n",
    "            # Add metadata to each chunk\n",
    "            for text in texts:\n",
    "                text.metadata = {\"audio_url\": audio_path}\n",
    "            \n",
    "            # Extend the list with these chunks\n",
    "            audio_text_chunks.extend(texts)\n",
    "\n",
    "    return audio_text_chunks\n",
    "\n",
    "# Call the function with your directory path\n",
    "audio_docs = genenerate_audio_docs('/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Last summer, my family and I visited Russia. Even though none of us could read Russian, we did not have any trouble in figuring our way out. All thanks to Google's real-time translation of Russian boards into English. This is just one of the several applications of neural networks. Neural networks form the base of deep learning, a sub-filled machine learning, where the algorithms are inspired by the structure of the human brain. Neural networks take in data, train themselves to recognize the patterns in this data, and then predict the outputs for a new set of similar data. Let's understand how this is done. Let's construct a neural network that differentiates between a square, circle, and triangle. Neural networks are made up of layers of neurons. These neurons are the core processing units of the network. First, we have the input layer, which receives the input. The output layer predicts our final output. In between exist the hidden layers which perform most of the computations' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/NN-audio.mp3'}\n",
      "page_content='required by our network. Here's an image of a circle. This image is composed of 28x28 pixels, which make up for 784 pixels. Each pixel is fed as input to each neuron of the first layer. Neurons of one layer are connected to neurons of the next layer through channels. Each of these channels is assigned a numerical value known as weight. The inputs are multiplied to the corresponding weights, and their sum is sent as input to the neurons in the hidden layer. Each of these neurons is associated with a numerical value called the bias, which is then added to the input sum. This value is then passed through a threshold function called the activation function. The result of the activation function determines if the particular neuron will get activated or not. An activated neuron transmits data to the neurons of the next layer over the channels. In this manner, the data is propagated through the network. This is called forward propagation. In the output layer, the neuron with the highest' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/NN-audio.mp3'}\n",
      "page_content='value fires and determines the output. The values are basically a probability. For example, here our neuron associated with square has the highest probability. Hence, that's the output predicted by the neural network. Of course, just by a look at it, we know our neural network has made a wrong prediction. But how does the network figure this out? Note that our network is yet to be trained. During this training process, along with the input, our network also has the output fed to it. The predicted output is compared against the actual output to realize the error in prediction. The magnitude of the error indicates how wrong we are, and the signs suggest if our predicted values are higher or lower than expected. The arrows here give an indication of the direction and magnitude of change to reduce the error. This information is then transferred backward through our network. This is known as back propagation. Now, based on this information, the weights are adjusted. This cycle of forward' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/NN-audio.mp3'}\n",
      "page_content='propagation and back propagation is iteratively performed with multiple inputs. This process continues until our weights are assigned such that the network can predict the shapes correctly in most of the cases. This brings our training process to an end. You might wonder how long this training process takes. Honestly, neural networks may take hours or even months to train. But time is a reasonable trade-off when compared to its scope. Let us look at some of the prime applications of neural networks. Facial recognition. Cameras on smartphones these days can estimate the age of the person based on their facial features. This is neural networks at play, first differentiating the face from the background, and then correlating the lines and spots on your face to a possible age. Workcasting. Neural networks are trained to understand the patterns and detect the possibility of rainfall or arise in stock prices with high accuracy. Music composition. Neural networks can even learn patterns in' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/NN-audio.mp3'}\n",
      "page_content='music and train itself enough to compose a fresh tune. So, here is a question for you. Which of the following statements does not hold true? A, activation functions are threshold functions. B, errors calculated at each layer of the neural network. C, both forward and back propagation take place during the training process of a neural network. D, most of the data processing is carried out in the hidden layers. Leave your answers in the comment section below. Three of you stand a chance to win Amazon vouchers. So don't miss it. With deep learning and neural networks, we are still taking baby steps. The growth in this field has been foreseen by the big names. Companies such as Google, Amazon, and Nvidia have invested in developing products such as libraries, predictive models, and intuitive GPUs that support the implementation of neural networks. The question dividing the visionaries is on the reach of neural networks. To what extent can we replicate the human brain? We'd have to wait a' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/NN-audio.mp3'}\n",
      "page_content='few more years to give a definite answer. But if you enjoyed this video, it would only take a few seconds to like and share it. Also, if you haven't yet, do subscribe to our channel and hit the bell icon as we have a lot more exciting videos coming up. Fun learning till then.' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/NN-audio.mp3'}\n",
      "page_content='In cell biology, one distinguishes between pro-cariotic and eukaryotic cells. One type of eukaryotic cell is the animal cell. There are a lot of essential compartments within the animal cell which fulfill diverse functions. But before we come to that, please subscribe to the channel. It is for free, but helps a lot. With a monthly subscription, you can also become a member of this channel now. And please use this form of support only if you have enough money to spend. The animal cell is surrounded by a plasma membrane. This structure is a phospholipid double layer which is considered selectively permeable. Certain molecules can pass through and others cannot pass. The main function of the plasma membrane is to regulate nutrient and mineral transport. Inside the plasma membrane lies the cytoplasm. The cytoplasm is filled with cytosol. This fluid contains nutrients and the structures referred to as organelles. Among these, the nucleus might be one of the most iconic cell compartments.' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the ANIMAL CELL explained (Organelles).mp3'}\n",
      "page_content='The nucleus stores the majority of the genetic information in form of DNA. Within the nucleus, important processes take place. Replication to duplicate DNA and transcription to generate RNA. There is another structure located inside the nucleus. The nucleus. One among the functions is the production and assembly of the important ribosomes which will be mentioned again in a minute. The membrane of the nucleus is connected to a membrane of another cell organelle. This is the so-called endoplasmic reticulum. It abbreviated with ER. One distinguishes between the rough ER that has a granular structure because it is partly coated with little ribosomes and there is a smooth ER. There are of course also free ribosomes in the cytoplasm. At the rough ER, protein synthesis but also protein modification and preparation for their transport take place. At the smooth ER, proteins can be modified further. In addition, lipid synthesis occurs here as well. The newly synthesized or modified proteins' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the ANIMAL CELL explained (Organelles).mp3'}\n",
      "page_content='need to be transported to their point of destination. This is one of many functions that is overtaken by the Golgi apparatus. Here proteins are taken up from the rough ER. The proteins are sorted, packaged and sent to their respective location. Further, modifications such as glycosylation take place at the Golgi. Animal cells also possess lysosomes. A lysosome is a spherical organelle enclosed by a membrane. Inside are digestive enzymes that break down unwanted parts of the cell or foreign molecules. A low pH is of great importance for the digestion. Myocondria are among the most prominent organelles as they are known as the power supply of the cell. These organelles provide the energy that is fuel for the cell's biochemical processes. ATP, the energy currency of the cell, is assembled here. Paroxysomes are organelles that can accumulate and degrade peroxides. Paroxides can be dangerous to other cell compartments. Hydrogen peroxide is an unavoidable byproduct of biochemical reactions.' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the ANIMAL CELL explained (Organelles).mp3'}\n",
      "page_content='So, peroxysomes kind of diffuse this danger. Euchariotic cells also possess a cytoskeleton. In animal cells, the cytoskeleton can be subdivided into three categories. Microtubules, actin filaments, and intermediate filaments. The cytoskeleton contributes to the cell's shape and to the organization and movement of the organelles inside. But the cytoskeleton does also take part in the cell's motility itself. A special organelle of the animal cell is the centrosome. The centrosome can be seen as the production site of microtubules. The centrosome supports the structure of the cell and fulfills essential organizational functions during cell division. This was a brief and simplified overview of a typical animal cell. If you are curious how a typical plant cell is structured, you may check out this video here. Please like the video if it was helpful to you and don't forget to subscribe to the channel. Bye.' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the ANIMAL CELL explained (Organelles).mp3'}\n",
      "page_content='In cell biology, one distinguishes between pro-cariotic and eukaryotic cells. One type of eukaryotic cell and the functional basic unit of plants is the plant cell. There are a lot of important components within the plant cell, which fulfill diverse functions. But before we come to that, please subscribe to the channel. It is for free, but helps me a lot. With a monthly subscription, you can also become a member of this channel now. Please use this form of support only if you have enough money to spend. One of the various distinct features of the plant cell is found around the cell itself, the cell wall. This structure functions as a support skeleton and determines the shape of the cell. Further, the cell wall is a well-suited natural barrier against infections of fungi. The cell wall is composed of cellulose embedded in a net with other complex polysaccharides and proteins. The plant cell wall is a strong structure that needs to be sufficient to withstand the high osmotic pressure' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the PLANT CELL explained (Organelles).mp3'}\n",
      "page_content='that is present inside the cell. As for all eukaryotic cells, plant cells also possess a plasma membrane. This structure out of lipids is selectively permeable. Certain molecules can pass through and others cannot enter or exit. The main function of the plasma membrane is to regulate nutrient and mineral transport. Inside the plasma membrane lies the cytoplasm. Cytoplasm is described as the totality of both. Cytosol, eliquid containing the nutrients, the cytoskeleton and the organelles of a cell. Among these, the nucleus might be one of the most well-known cell compartments. The nucleus stores the majority of the genetic information packed in DNA. Within the nucleus, important processes take place. The nucleus is located in the nucleus, and the nucleus is located in the nucleus. The nucleus is located in the nucleus, and the nucleus is located in the nucleus. Among the functions is the production and assembly of the important ribosomes, which will be mentioned again in a minute. The' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the PLANT CELL explained (Organelles).mp3'}\n",
      "page_content='membrane of the nucleus is connected to a membrane of another cell organelle. This is the so-called endoplasmic reticulum, abbreviated with ER. One distinguishes between the rough ER that has its granular structure because it is partly coated with ribosomes, and there is the smooth ER. The ER, of course, also free ribosomes in the cytoplasm. At the rough ER, protein synthesis, but also protein modification and preparation for the transport take place. At the smooth ER, proteins are also modified. In addition, lipid synthesis occurs here. The newly synthesized or modified proteins need to be transported to their point of destination. This is one of many functions that is overtaken by the Golgi apparatus. Here, proteins that come from the rough ER are taken up. The proteins are sorted, packaged, and sent to their respective location. At the Golgi, the proteins might also be modified further. Glycosolation, for example, might take place here. The iconic plant cell wall also relies on the' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the PLANT CELL explained (Organelles).mp3'}\n",
      "page_content='Golgi. Polysaccharides are synthesized here. The secret of a leaf-screen color lies in chlorophyll. This is found in an organelle named the chloroplast. Photothynthesis is a feature that makes plant cells so special. Inside the chloroplasts is where the magic happens. Sunlight, water, and carbon dioxide are used to produce energy in form of sugars and indirectly oxygen is produced, which may be the most important byproduct for us humans. Some plant cells also possess a different type of plastic. The amyloplest is responsible for the storage of starch, an important polysaccharide. Mytochondria are the powerhouse of the cell. Sounds familiar, but why? These organelles provide the energy needed to power the cell's biochemical reactions. Paroxysomes are organelles that can accumulate and degrade parasites that can be dangerous to other cell compartments. Hydrogen peroxide, for instance, is an unavoidable byproduct of biochemical reactions. Plant cells have a gigantic permanent vacuole' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the PLANT CELL explained (Organelles).mp3'}\n",
      "page_content='that can take up to 90% of the total cell volume in plants. This special organelle is water-filled volume surrounded by a membrane known as the tonoplast. The vacuole has a whole bunch of different functions. It maintains the internal pressure, called turgor, and contributes to the cell's total stability. It is also seen as a large trash can that can digest waste inside the cell. Last but not least, one should mention the cytoskeleton. In plants, the cytoskeleton is mainly composed of microtubules and active filaments. The cytoskeleton contributes to the cell's shape and to the organization and movement of the organelles inside. This was a brief and simplified overview of a typical plant cell. If you are curious how an animal cell is structured, you may check out this video here. Please like the video if it was helpful to you and don't forget to subscribe to the channel. Bye!' metadata={'audio_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/audio/Structure and Function of the PLANT CELL explained (Organelles).mp3'}\n"
     ]
    }
   ],
   "source": [
    "for audio in audio_docs:\n",
    "    print(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Image documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_google_vertexai in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (1.0.10)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.56.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_google_vertexai) (1.63.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.17.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_google_vertexai) (2.18.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_google_vertexai) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_google_vertexai) (0.4.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.33 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain_google_vertexai) (0.2.33)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.19.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (4.25.4)\n",
      "Requirement already satisfied: packaging>=14.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.12.5)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.8.2)\n",
      "Requirement already satisfied: docstring-parser<1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.16)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (1.5.0)\n",
      "Requirement already satisfied: anyio in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (0.1.99)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (4.12.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.63.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.65.5)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.13.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain_google_vertexai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.17.0->langchain_google_vertexai) (2.2.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.26.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->langchain_google_vertexai) (1.2.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain_google_vertexai) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-generativeai in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (0.7.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-generativeai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-generativeai) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-generativeai) (2.141.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-generativeai) (2.34.0)\n",
      "Requirement already satisfied: protobuf in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-generativeai) (4.25.4)\n",
      "Requirement already satisfied: pydantic in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.65.5)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (10.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_google_vertexai \n",
    "%pip install google-generativeai\n",
    "%pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"trans-array-427509-h2\"\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID,location=REGION)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "from langchain_google_vertexai import VertexAI, ChatVertexAI, VertexAIEmbeddings\n",
    "import langchain_core \n",
    "import google.generativeai as genai\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "PDFPageCountError",
     "evalue": "Unable to get page count.\nI/O Error: Couldn't open file '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/a_level_biology.pdf': No such file or directory.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/pdf2image/pdf2image.py:602\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m d:\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "\u001b[0;31mValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPDFPageCountError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Extract elements and images\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m raw_pdf_elements \u001b[38;5;241m=\u001b[39m \u001b[43mpartition_pdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_level_biology.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunking_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mby_title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_after_n_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombine_text_under_n_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_output_dir_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured/documents/elements.py:605\u001b[0m, in \u001b[0;36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[0;32m--> 605\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m     call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    608\u001b[0m     regex_metadata: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m call_args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregex_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured/file_utils/filetype.py:706\u001b[0m, in \u001b[0;36madd_filetype.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[0;32m--> 706\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     params \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    708\u001b[0m     include_metadata \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured/file_utils/filetype.py:662\u001b[0m, in \u001b[0;36madd_metadata.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[0;32m--> 662\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m     call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    664\u001b[0m     include_metadata \u001b[38;5;241m=\u001b[39m call_args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured/chunking/dispatch.py:74\u001b[0m, in \u001b[0;36madd_chunking_strategy.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The decorated function is replaced with this one.\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# -- call the partitioning function to get the elements --\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# -- look for a chunking-strategy argument --\u001b[39;00m\n\u001b[1;32m     77\u001b[0m call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured/partition/pdf.py:210\u001b[0m, in \u001b[0;36mpartition_pdf\u001b[0;34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, include_metadata, metadata_filename, metadata_last_modified, chunking_strategy, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, starting_page_number, extract_forms, form_extraction_skip_tables, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m exactly_one(filename\u001b[38;5;241m=\u001b[39mfilename, file\u001b[38;5;241m=\u001b[39mfile)\n\u001b[1;32m    208\u001b[0m languages \u001b[38;5;241m=\u001b[39m check_language_args(languages \u001b[38;5;129;01mor\u001b[39;00m [], ocr_languages)\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition_pdf_or_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_from_file_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_from_file_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_forms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured/partition/pdf.py:312\u001b[0m, in \u001b[0;36mpartition_pdf_or_image\u001b[0;34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, languages, metadata_last_modified, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, starting_page_number, extract_forms, form_extraction_skip_tables, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    311\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 312\u001b[0m         elements \u001b[38;5;241m=\u001b[39m \u001b[43m_partition_pdf_or_image_local\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspooled_to_bytes_io_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m            \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlast_modification_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_forms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m            \u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m         out_elements \u001b[38;5;241m=\u001b[39m _process_uncategorized_text_elements(elements)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m PartitionStrategy\u001b[38;5;241m.\u001b[39mFAST:\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured/utils.py:217\u001b[0m, in \u001b[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs):\n\u001b[1;32m    216\u001b[0m     run_check()\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured/partition/pdf.py:600\u001b[0m, in \u001b[0;36m_partition_pdf_or_image_local\u001b[0;34m(filename, file, is_image, infer_table_structure, include_page_breaks, languages, ocr_languages, ocr_mode, model_name, hi_res_model_name, pdf_image_dpi, metadata_last_modified, pdf_text_extractable, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, analysis, analyzed_image_output_dir_path, starting_page_number, extract_forms, form_extraction_skip_tables, pdf_hi_res_max_pages, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m skip_dump_od \u001b[38;5;241m=\u001b[39m env_config\u001b[38;5;241m.\u001b[39mANALYSIS_DUMP_OD_SKIP\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     inferred_document_layout \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_file_with_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hi_res_model_name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchipper\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;66;03m# NOTE(alan): We shouldn't do OCR with chipper\u001b[39;00m\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;66;03m# NOTE(antonio): We shouldn't do PDFMiner with chipper\u001b[39;00m\n\u001b[1;32m    610\u001b[0m         final_document_layout \u001b[38;5;241m=\u001b[39m inferred_document_layout\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:370\u001b[0m, in \u001b[0;36mprocess_file_with_model\u001b[0;34m(filename, model_name, is_image, fixed_layouts, pdf_image_dpi, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    362\u001b[0m layout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    363\u001b[0m     DocumentLayout\u001b[38;5;241m.\u001b[39mfrom_image_file(\n\u001b[1;32m    364\u001b[0m         filename,\n\u001b[1;32m    365\u001b[0m         detection_model\u001b[38;5;241m=\u001b[39mdetection_model,\n\u001b[1;32m    366\u001b[0m         element_extraction_model\u001b[38;5;241m=\u001b[39melement_extraction_model,\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    368\u001b[0m     )\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_image\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDocumentLayout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetection_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetection_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement_extraction_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_extraction_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m )\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layout\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:62\u001b[0m, in \u001b[0;36mDocumentLayout.from_file\u001b[0;34m(cls, filename, fixed_layouts, pdf_image_dpi, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading PDF for file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[0;32m---> 62\u001b[0m     _image_paths \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_pdf_to_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     image_paths \u001b[38;5;241m=\u001b[39m cast(List[\u001b[38;5;28mstr\u001b[39m], _image_paths)\n\u001b[1;32m     69\u001b[0m     number_of_pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(image_paths)\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:394\u001b[0m, in \u001b[0;36mconvert_pdf_to_image\u001b[0;34m(filename, dpi, output_folder, path_only)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_folder must be specified if path_only is true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mpdf2image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpaths_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     images \u001b[38;5;241m=\u001b[39m pdf2image\u001b[38;5;241m.\u001b[39mconvert_from_path(\n\u001b[1;32m    402\u001b[0m         filename,\n\u001b[1;32m    403\u001b[0m         dpi\u001b[38;5;241m=\u001b[39mdpi,\n\u001b[1;32m    404\u001b[0m         paths_only\u001b[38;5;241m=\u001b[39mpath_only,\n\u001b[1;32m    405\u001b[0m     )\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/pdf2image/pdf2image.py:127\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[0;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(poppler_path, PurePath):\n\u001b[1;32m    125\u001b[0m     poppler_path \u001b[38;5;241m=\u001b[39m poppler_path\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m--> 127\u001b[0m page_count \u001b[38;5;241m=\u001b[39m \u001b[43mpdfinfo_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserpw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mownerpw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoppler_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoppler_path\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# We start by getting the output format, the buffer processing function and if we need pdftocairo\u001b[39;00m\n\u001b[1;32m    132\u001b[0m parsed_fmt, final_extension, parse_buffer_func, use_pdfcairo_format \u001b[38;5;241m=\u001b[39m _parse_format(\n\u001b[1;32m    133\u001b[0m     fmt, grayscale\n\u001b[1;32m    134\u001b[0m )\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/pdf2image/pdf2image.py:611\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFInfoNotInstalledError(\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count. Is poppler installed and in PATH?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFPageCountError(\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m     )\n",
      "\u001b[0;31mPDFPageCountError\u001b[0m: Unable to get page count.\nI/O Error: Couldn't open file '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/a_level_biology.pdf': No such file or directory.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from PIL import Image\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "\n",
    "input_path = \"/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/\"\n",
    "output_path = '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures'\n",
    "\n",
    "# Extract elements and images\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=os.path.join(input_path, \"a_level_biology.pdf\"),\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=output_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "#Creating image summaries\n",
    "def genenerate_image_summaries(img_dir):\n",
    "    img_paths = []\n",
    "    image_summaries = []\n",
    "\n",
    "    model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n",
    "    prompt = \"\"\"You are a curriculum instructor tasked with summarizing images for retrieval and in assisting in generating quiz questions.\\\n",
    "        These summaries will be embedded and usd ot retrieve the raw image.\\\n",
    "            Describe consisely the contents of the images and describe the characteristics of each component of the image. Do not infer what the image means unless it is for analysing mathematical graphs.\"\"\"\n",
    "\n",
    "    for filename in sorted(os.listdir(img_dir)):\n",
    "      print(filename)\n",
    "      if filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(img_dir,filename)\n",
    "        img_paths.append(image_path)\n",
    "        img = Image(image_path) \n",
    "        response = model.generate_content([prompt,img])\n",
    "        image_summaries.append(response)\n",
    "    return image_summaries,img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell1.png\n",
      "cell2.png\n",
      "eye1.png\n",
      "figure-2-1.png\n",
      "figure-2-2.png\n",
      "figure-3-3.png\n"
     ]
    }
   ],
   "source": [
    "image_dir = '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images'\n",
    "image_summaries,img = genenerate_image_summaries(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/cell1.png', '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/cell2.png', '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/eye1.png', '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-2-1.png', '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-2-2.png', '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-3-3.png']\n",
      "The image is a scatter plot with data points clustered in the bottom left corner and a positive linear trend. A straight line is drawn through the data, indicating a positive correlation. The majority of the asterisks are concentrated at the origin of the graph, with a few outliers scattered further out. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(image_summaries))\n",
    "print(img)\n",
    "print(image_summaries[4].candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_summaries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     img_docs\u001b[38;5;241m.\u001b[39mappend(img_doc)\n\u001b[1;32m     16\u001b[0m  \u001b[38;5;28;01mreturn\u001b[39;00m img_docs\n\u001b[0;32m---> 18\u001b[0m image_docs \u001b[38;5;241m=\u001b[39m generate_image_documents(image_summaries\u001b[38;5;241m=\u001b[39m\u001b[43mimage_summaries\u001b[49m,image_paths\u001b[38;5;241m=\u001b[39mimg)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_docs[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_summaries' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_image_documents(image_paths:list,image_summaries:list):\n",
    " img_summaries = []\n",
    " #extracts only the summary text from the llm response\n",
    " for summary in image_summaries:\n",
    "    img_summary = summary.candidates[0].content.parts[0].text\n",
    "    img_summaries.append(img_summary)\n",
    "\n",
    "#creates document object with image summary and image path\n",
    " img_docs = []\n",
    " for i in range(len(img_summaries)):\n",
    "    summary = img_summaries[i]\n",
    "    metadata = image_paths[i]\n",
    "    img_doc = Document(page_content=summary,metadata={\"image_url\":metadata})\n",
    "    img_docs.append(img_doc)\n",
    "    \n",
    " return img_docs\n",
    "\n",
    "image_docs = generate_image_documents(image_summaries=image_summaries,image_paths=img)\n",
    "print(image_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724878698.008244  106216 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "from tools import RAGpipeline\n",
    "docs =[]\n",
    "docs = image_docs + audio_docs\n",
    "# for doc in docs:\n",
    "#     print(doc)\n",
    "rag = RAGpipeline()\n",
    "db = rag.create_vectorstore(documents=docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724878705.019480  106216 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Which of the following is NOT a component of the animal cell?', 'choices': [{'key': 'A', 'value': 'Plasma membrane'}, {'key': 'B', 'value': 'Cytoplasm'}, {'key': 'C', 'value': 'Cell wall'}, {'key': 'D', 'value': 'Nucleus'}], 'answer': 'C', 'explanation': 'Animal cells do not have a cell wall, unlike plant cells.'}\n",
      "{'question': 'Which of the following is a structure found in animal cells but not in plant cells?', 'choices': [{'key': 'A', 'value': 'Cell wall'}, {'key': 'B', 'value': 'Centrosome'}, {'key': 'C', 'value': 'Chloroplast'}, {'key': 'D', 'value': 'Nucleus'}], 'answer': 'C', 'explanation': 'Chloroplasts are organelles found in plant cells that are responsible for photosynthesis. Animal cells do not have chloroplasts because they do not photosynthesize.'}\n",
      "{'question': 'Which of the following is a function of the plasma membrane in an animal cell?', 'choices': [{'key': 'A', 'value': 'Regulate nutrient and mineral transport'}, {'key': 'B', 'value': 'Produce ATP'}, {'key': 'C', 'value': 'Break down unwanted parts of the cell'}, {'key': 'D', 'value': 'Support the structure of the cell'}], 'answer': 'A', 'explanation': 'The plasma membrane is a selectively permeable phospholipid double layer that regulates the transport of nutrients and minerals into and out of the cell.'}\n"
     ]
    }
   ],
   "source": [
    "from tools import QuizBuilder\n",
    "\n",
    "ques_gen = QuizBuilder(vectorstore=db,topic=\"animal cell\")\n",
    "questions = ques_gen.create_questions(3)\n",
    "for q in questions:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /Users/mac/projects AI/kai-ai-backend/env/lib/python3.10/site-packages (10.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/a2t.ipynb\"), \"../../../\")))\n",
    "\n",
    "\n",
    "from app.services.logger import setup_logger\n",
    "from app.api.error_utilities import FileHandlerError, ImageHandlerError\n",
    "from langchain_community.document_loaders import YoutubeLoader, PyPDFLoader, TextLoader, UnstructuredURLLoader, UnstructuredPowerPointLoader, Docx2txtLoader, UnstructuredExcelLoader, UnstructuredXMLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "import requests\n",
    "import tempfile\n",
    "import google.generativeai as genai\n",
    "from typing import Any\n",
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from PIL import Image\n",
    "import ssl\n",
    "\n",
    "\n",
    "logger = setup_logger(__name__)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "def genenerate_image_summaries(img_dir):\n",
    "   img_paths = []\n",
    "   image_summaries = []\n",
    "\n",
    "\n",
    "   model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n",
    "   prompt = \"\"\"You are a curriculum instructor tasked with summarizing images for retrieval and in assisting in generating quiz questions.\\\n",
    "       These summaries will be embedded and usd ot retrieve the raw image.\\\n",
    "           Describe consisely the contents of the images and describe the characteristics of each component of the image. Do not infer what the image means unless it is for analysing mathematical graphs.\"\"\"\n",
    "\n",
    "\n",
    "   for filename in sorted(os.listdir(img_dir)):\n",
    "     print(filename)\n",
    "     if filename.endswith(\".jpg\"):\n",
    "       image_path = os.path.join(img_dir,filename)\n",
    "       img_paths.append(image_path)\n",
    "       img = Image.open(image_path)\n",
    "       response = model.generate_content([prompt,img])\n",
    "       image_summaries.append(response)\n",
    "   img_summaries = []\n",
    "\n",
    "#extracts only the summary text from the llm response\n",
    "   for summary in image_summaries:\n",
    "     img_summary = summary.candidates[0].content.parts[0].text\n",
    "     img_summaries.append(img_summary)\n",
    "\n",
    "\n",
    "#creates document object with image summary and image path\n",
    "   img_docs = []\n",
    "   for i in range(len(img_summaries)):\n",
    "     summary = img_summaries[i]\n",
    "     metadata = img_paths[i]\n",
    "     img_doc = Document(page_content=summary,metadata={\"image_url\":metadata})\n",
    "     img_docs.append(img_doc)\n",
    "  \n",
    "   return img_docs\n",
    "\n",
    "class FileHandler:\n",
    "    def __init__(self, file_loader, file_extension):\n",
    "        self.file_loader = file_loader\n",
    "        self.file_extension = file_extension\n",
    "\n",
    "    def load(self, url):\n",
    "        # Generate a unique filename with a UUID prefix\n",
    "        unique_filename = f\"{uuid.uuid4()}.{self.file_extension}\"\n",
    "\n",
    "        # Download the file from the URL and save it to a temporary file\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(delete=False, prefix=unique_filename) as temp_file:\n",
    "            temp_file.write(response.content)\n",
    "            temp_file_path = temp_file.name\n",
    "\n",
    "        # Use the file_loader to load the documents\n",
    "        try:\n",
    "            loader = self.file_loader(file_path=temp_file_path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"No such file found at {temp_file_path}\")\n",
    "            raise FileHandlerError(f\"No file found\", temp_file_path) from e\n",
    "\n",
    "        try:\n",
    "            documents = loader.load()\n",
    "            if self.file_extension == \"pdf\":\n",
    "             raw_pdf_elements = partition_pdf(\n",
    "               filename=temp_file_path,\n",
    "               extract_images_in_pdf=True,\n",
    "               infer_table_structure=True,\n",
    "               chunking_strategy=\"by_title\",\n",
    "               max_characters=4000,\n",
    "               new_after_n_chars=3800,\n",
    "               combine_text_under_n_chars=2000,\n",
    "               image_output_dir_path=\"/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures\"\n",
    ")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"File content might be private or unavailable or the URL is incorrect.\")\n",
    "            raise FileHandlerError(f\"No file content available\", temp_file_path) from e\n",
    "\n",
    "        # Remove the temporary file\n",
    "        os.remove(temp_file_path)\n",
    "\n",
    "        return documents\n",
    "    \n",
    "def load_pdf_documents(pdf_url: str, verbose=False):\n",
    "    pdf_loader = FileHandler(PyPDFLoader, \"pdf\")\n",
    "    docs = pdf_loader.load(pdf_url)\n",
    "    image_dir =\"/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures\"\n",
    "    #extracting images from the pdf and storing them in a directory\n",
    "    image_docs = genenerate_image_summaries(image_dir)\n",
    "\n",
    "    if docs:\n",
    "        split_docs = splitter.split_documents(docs)\n",
    "\n",
    "        if verbose:\n",
    "            logger.info(f\"Found PDF file\")\n",
    "            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n",
    "\n",
    "        return image_docs + docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure-2-1.jpg\n",
      "figure-2-2.jpg\n",
      "figure-3-3.jpg\n",
      "page_content='The image is a scatter plot with a line of best fit. Most data points cluster around the origin and bottom left of the plot in a tight distribution. There are four outlier points, one at (50,10000), (500, 35000), (300, 5000) and (30, 12500). The line of best fit goes from the origin to (500, 28000) and has a positive slope.  \n",
      "' metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures/figure-2-1.jpg'}\n",
      "page_content='The image shows a scatter plot with a line running through the data points. The data points are represented by asterisks and are clustered towards the bottom left corner of the plot, with a few outliers scattered further out. A straight line is drawn through the data, rising steadily from left to right. \n",
      "' metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures/figure-2-2.jpg'}\n",
      "page_content='The image is a scatter plot on a cartesian plane with the X axis ranging from 0 to 500 and the Y axis ranging from -10000 to 10000. There are 15 data points on the graph, all denoted by squares, that appear randomly plotted with a slight cluster  between X = 0 and X = 50. \n",
      "' metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures/figure-3-3.jpg'}\n",
      "page_content='Linear  Regr ession\n",
      "Linear regression attempts to model the relationship between two variables by fitting a linear equation to\n",
      "observed data. One variable is considered to be an explanatory variable, and the other is considered to be a\n",
      "dependent variable. For example, a modeler might want to relate the weights of individuals to their heights using\n",
      "a linear regression model.\n",
      "Before attempting to fit a linear model to observed data, a modeler should first determine whether or not there is\n",
      "a relationship between the variables of interest. This does not necessarily imply that one variable causes  the\n",
      "other (for example, higher SA T scores do not cause  higher college grades), but that there is some significant\n",
      "association between the two variables. A scatterplot  can be a helpful tool in determining the strength of the\n",
      "relationship between two variables. If there appears to be no association between the proposed explanatory and\n",
      "dependent variables (i.e., the scatterplot does not indicate any increasing or decreasing trends), then fitting a\n",
      "linear regression model to the data probably will not provide a useful model. A valuable numerical measure of\n",
      "association between two variables is the correlation coef ficient , which is a value between -1 and 1 indicating the\n",
      "strength of the association of the observed data for the two variables.\n",
      "A linear regression line has an equation of the form Y = a + bX , where X is the explanatory variable and Y is the\n",
      "dependent variable. The slope of the line is b, and a is the intercept (the value of y when x = 0).\n",
      "Least-Squar es Regr ession\n",
      "The most common method for fitting a regression line is the method of least-squares. This method calculates the\n",
      "best-fitting line for the observed data by minimizing the sum of the squares of the vertical deviations from each\n",
      "data point to the line (if a point lies on the fitted line exactly , then its vertical deviation is 0). Because the\n",
      "deviations are first squared, then summed, there are no cancellations between positive and negative values.\n",
      "Example\n",
      "The dataset \"T elevisions, Physicians, and Life Expectancy\" contains, among other variables, the number of\n",
      "people per television set and the number of people per physician for 40 countries. Since both variables probably\n",
      "reflect the level of wealth in each country , it is reasonable to assume that there is some positive association\n",
      "between them. After removing 8 countries with missing values from the dataset, the remaining 32 countries have\n",
      "a correlation coef ficient of 0.852 for number of people per television set and number of people per physician.\n",
      "The r² value is 0.726 (the square of the correlation coef ficient), indicating that 72.6% of the variation in one\n",
      "variable may be explained by the other . (Note: see correlation  for mor e detail.)  Suppose we choose to consider\n",
      "number of people per television set as the explanatory variable, and number of people per physician as the\n",
      "dependent variable. Using the MINIT AB \"REGRESS\" command gives the following results:\n",
      "The regression equation is People.Phys. = 1019 + 56.2 People.Tel.\n",
      "To view the fit of the model to the observed data, one may plot the computed regression line over the actual data\n",
      "points to evaluate the results. For this example, the plot appears to the right, with number of individuals per\n",
      "television set (the explanatory variable) on the x-axis and number of individuals per physician (the dependent\n",
      "variable) on the y-axis. While most of the data points are clustered towards the lower left corner of the plot\n",
      "(indicating relatively few individuals per television set and per physician), there are a few points which lie far\n",
      "away from the main cluster of the data. These points are known as outliers , and depending on their location may\n",
      "have a major impact on the regression line (see below).' metadata={'source': '/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/be469aba-3b6f-46d5-b7d3-63fa34867f52.pdf9nmvctfe', 'page': 0}\n",
      "page_content='Data sour ce: The W orld Almanac and Book of Facts 1993  (1993), New Y ork: Phar os Books. Dataset available\n",
      "through the JSE Dataset Archive .\n",
      "Outliers and Influential Observations\n",
      "After a regression line has been computed for a group of data, a point which lies far from the line (and thus has a\n",
      "large residual value) is known as an outlier . Such points may represent erroneous data, or may indicate a poorly\n",
      "fitting regression line. If a point lies far from the other data in the horizontal direction, it is known as an\n",
      "influential observation . The reason for this distinction is that these points have may have a significant impact on\n",
      "the slope of the regression line. Notice, in the above example, the ef fect of removing the observation in the upper\n",
      "right corner of the plot:\n",
      "With this influential observation removed, the\n",
      "regression equation is now\n",
      " People.Phys = 1650 + 21.3 People.Tel. \n",
      "The correlation between the two variables has\n",
      "dropped to 0.427, which reduces the r² value to\n",
      "0.182. With this influential observation removed,\n",
      "less that 20% of the variation in number of\n",
      "people per physician may be explained by the\n",
      "number of people per television. Influential\n",
      "observations are also visible in the new model,\n",
      "and their impact should also be investigated.\n",
      "Residuals\n",
      "Once a regression model has been fit to a group of data, examination of the residuals (the deviations from the\n",
      "fitted line to the observed values) allows the modeler to investigate the validity of his or her assumption that a\n",
      "linear relationship exists. Plotting the residuals on the y-axis against the explanatory variable on the x-axis\n",
      "reveals any possible non-linear relationship among the variables, or might alert the modeler to investigate\n",
      "lurking variables . In our example, the residual plot amplifies the presence of outliers.' metadata={'source': '/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/be469aba-3b6f-46d5-b7d3-63fa34867f52.pdf9nmvctfe', 'page': 1}\n",
      "page_content='Lurking Variables\n",
      "If non-linear trends are visible in the relationship between an explanatory and dependent variable, there may be\n",
      "other influential variables to consider . A lurking variable  exists when the relationship between two variables is\n",
      "significantly af fected by the presence of a third variable which has not been included in the modeling ef fort.\n",
      "Since such a variable might be a factor of time (for example, the ef fect of political or economic cycles), a time\n",
      "series plot of the data is often a useful tool in identifying the presence of lurking variables.\n",
      "Extrapolation\n",
      "Whenever a linear regression model is fit to a group of data, the range of the data should be carefully observed.\n",
      "Attempting to use a regression equation to predict values outside of this range is often inappropriate, and may\n",
      "yield incredible answers. This practice is known as extrapolation . Consider , for example, a linear model which\n",
      "relates weight gain to age for young children. Applying such a model to adults, or even teenagers, would be\n",
      "absurd, since the relationship between age and weight gain is not consistent for all age groups.' metadata={'source': '/var/folders/cc/s9_513mj5792gjszdp0psy3h0000gn/T/be469aba-3b6f-46d5-b7d3-63fa34867f52.pdf9nmvctfe', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://firebasestorage.googleapis.com/v0/b/kai-ai-f63c8.appspot.com/o/uploads%2F510f946e-823f-42d7-b95d-d16925293946-Linear%20Regression%20Stat%20Yale.pdf?alt=media&token=caea86aa-c06b-4cde-9fd0-42962eb72ddd\"\n",
    "docs = load_pdf_documents(url)\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure-2-1.jpg\n",
      "figure-2-2.jpg\n",
      "figure-3-3.jpg\n",
      "[Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures/figure-2-1.jpg'}, page_content='The image is a scatter plot with data points represented by asterisks. A straight line passes through the data points, suggesting a linear relationship. Most data points are clustered towards the origin (bottom-left corner) with several outliers scattered farther away. One outlier is located around the coordinates (300, 6000) while another one is around (500, 35000). \\n'), Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures/figure-2-2.jpg'}, page_content='The image is a scatter plot with a line passing through it.  The data points are represented by asterisks and are concentrated towards the bottom left of the graph with a few outliers. A straight line is drawn across the graph passing close to the cluster of data points and it can be inferred to be a line of best fit. \\n'), Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures/figure-3-3.jpg'}, page_content='The image is a scatter plot with black square markers on a white background.  The x axis ranges from 0 to 500 and the y axis ranges from -10000 to 10000. There is a cluster of markers near the origin and a single marker near the top right corner of the plot.  The background features a light gray dotted grid pattern. \\n')]\n"
     ]
    }
   ],
   "source": [
    "image_docs = genenerate_image_summaries(\"/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/figures\")\n",
    "print(image_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = FileHandler(PyPDFLoader,\"pdf\")\n",
    "docs = pdf_loader.load(url)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "\n",
    "def load_docs_youtube_url(youtube_url: str, verbose=True) -> str:\n",
    "    \n",
    "    #load video as a temporary file\n",
    "    yt = YouTube(youtube_url,on_progress_callback=on_progress)\n",
    "    ys = yt.streams.get_highest_resolution()\n",
    "    ys.download(output_path=\"./video_data/videos\")\n",
    "    ys.download(output_path=\"./video_data/audios\",mp3=True)\n",
    "\n",
    "    extract_image_frames(\"./video_data/videos\")\n",
    "    \n",
    "    img_summaries = genenerate_image_summaries(\"./video_data/video_img\")\n",
    "\n",
    "    return img_summaries\n",
    "\n",
    "import cv2\n",
    "def extract_image_frames(vid_dir):\n",
    "    output_folder= \"./video_data/video_img\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in sorted(os.listdir(vid_dir)):\n",
    "        file_path = os.path.join(vid_dir,filename)\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_interval = int(fps*10)\n",
    "\n",
    "        count = 0\n",
    "        extracted_frames = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,count)\n",
    "            ret,frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_filename = os.path.join(output_folder,f\"frame_{extracted_frames}.jpg\")\n",
    "            cv2.imwrite(frame_filename,frame)\n",
    "            print(f\"saved: {frame_filename}\")\n",
    "            count+=frame_interval\n",
    "            extracted_frames+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: ./video_data/video_img/frame_0.jpg███████| 100.0%\n",
      "saved: ./video_data/video_img/frame_1.jpg\n",
      "saved: ./video_data/video_img/frame_2.jpg\n",
      "saved: ./video_data/video_img/frame_3.jpg\n",
      "saved: ./video_data/video_img/frame_4.jpg\n",
      "saved: ./video_data/video_img/frame_5.jpg\n",
      "saved: ./video_data/video_img/frame_6.jpg\n",
      "saved: ./video_data/video_img/frame_7.jpg\n",
      "saved: ./video_data/video_img/frame_8.jpg\n",
      "saved: ./video_data/video_img/frame_9.jpg\n",
      "saved: ./video_data/video_img/frame_10.jpg\n",
      "saved: ./video_data/video_img/frame_11.jpg\n",
      "saved: ./video_data/video_img/frame_12.jpg\n",
      "saved: ./video_data/video_img/frame_13.jpg\n",
      "saved: ./video_data/video_img/frame_14.jpg\n",
      "saved: ./video_data/video_img/frame_15.jpg\n",
      "saved: ./video_data/video_img/frame_16.jpg\n",
      "saved: ./video_data/video_img/frame_17.jpg\n",
      "saved: ./video_data/video_img/frame_18.jpg\n",
      "saved: ./video_data/video_img/frame_19.jpg\n",
      "saved: ./video_data/video_img/frame_20.jpg\n",
      "saved: ./video_data/video_img/frame_21.jpg\n",
      "saved: ./video_data/video_img/frame_22.jpg\n",
      "saved: ./video_data/video_img/frame_23.jpg\n",
      "saved: ./video_data/video_img/frame_24.jpg\n",
      "saved: ./video_data/video_img/frame_25.jpg\n",
      "saved: ./video_data/video_img/frame_26.jpg\n",
      "saved: ./video_data/video_img/frame_27.jpg\n",
      "frame_0.jpg\n",
      "frame_1.jpg\n",
      "frame_10.jpg\n",
      "frame_11.jpg\n",
      "frame_12.jpg\n",
      "frame_13.jpg\n",
      "frame_14.jpg\n",
      "frame_15.jpg\n",
      "frame_16.jpg\n",
      "frame_17.jpg\n",
      "frame_18.jpg\n",
      "frame_19.jpg\n",
      "frame_2.jpg\n",
      "frame_20.jpg\n",
      "frame_21.jpg\n",
      "frame_22.jpg\n",
      "frame_23.jpg\n",
      "frame_24.jpg\n",
      "frame_25.jpg\n",
      "frame_26.jpg\n",
      "frame_27.jpg\n",
      "frame_3.jpg\n",
      "frame_4.jpg\n",
      "frame_5.jpg\n",
      "frame_6.jpg\n",
      "frame_7.jpg\n",
      "frame_8.jpg\n",
      "frame_9.jpg\n",
      "[Document(metadata={'image_url': './video_data/video_img/frame_0.jpg'}, page_content='The image displays a simplified diagram of an animal cell. The cell is depicted as a circular structure, colored in light blue, and contains various organelles, each with a distinct shape, size, and color. \\n\\n* **Nucleus:**  A large, circular organelle located near the center of the cell, outlined in blue with a darker blue, speckled texture and containing a smaller, solid blue circle within it.\\n* **Endoplasmic Reticulum (ER):**  One section of ER is shown close to the nucleus, colored in light blue with darker blue squiggly lines within, giving it a rough appearance. Another section of ER is smoother in appearance, colored purple, and located further from the nucleus.\\n* **Golgi Apparatus:**  A stack of flattened, curved sacs colored in purple, positioned near the edge of the cell. \\n* **Mitochondria:** Four bean-shaped organelles with an orange outline and a lighter orange interior, scattered around the cell.\\n* **Lysosome:** A small, circular organelle colored orange, positioned near the edge of the cell.\\n* **Centrioles:** Two small, green and blue structures located near the nucleus.\\n* **Cytoplasm:**  The light blue background within the cell membrane, filling the space between the organelles.\\n* **Cell membrane:** A thin, dark blue line outlining the entire cell.\\n\\nThe title \"Animal Cell\" is printed above the diagram in bold, black letters. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_1.jpg'}, page_content='The image depicts a simplified model of an animal cell with its main organelles labeled. \\n\\nThe cell is represented as a circular shape, filled with a light blue cytosol. Inside the cell:\\n\\n* **Nucleus:** A large, circular organelle with a double membrane (represented by a darker blue outline with dashes). It contains a smaller, dark blue circle representing the nucleolus.\\n* **Endoplasmic Reticulum (ER):** A network of interconnected sacs and tubules. It is shown in two forms:\\n    * **Rough ER:** Located near the nucleus, depicted in blue with small dots representing ribosomes on its surface.\\n    * **Smooth ER:** Located further from the nucleus, shown as a series of interconnected purple lines.\\n* **Golgi Apparatus:** A stack of flattened, membrane-bound sacs (cisternae), depicted as curved purple lines.\\n* **Mitochondria:** Bean-shaped organelles with a double membrane (represented by an orange outer membrane and inner folded membrane).\\n* **Lysosomes:** Small, circular organelles depicted in green.\\n* **Vacuoles:** Small, orange circles scattered throughout the cytosol.\\n* **Ribosomes:** Small dots scattered throughout the cytosol and on the surface of the rough ER.\\n* **Centrioles:** Two small, cylindrical structures located near the nucleus, represented as red dots.\\n* **Cytoskeleton:** Represented by thin lines of various colors (green, red, blue) traversing the cytoplasm.\\n\\nThe title \"Animal Cell\" is prominently displayed at the top in bold black letters. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_10.jpg'}, page_content='The image depicts a simplified model of an animal cell. The cell is represented by a large circle filled with light blue. Inside the cell is a smaller circle outlined in blue with a dashed line, this is labeled \"Nucleolus\".  Within the smaller circle is a solid blue circle. This is connected by a thin black line to the label \"Nucleolus\" outside of the cell. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_11.jpg'}, page_content='The image depicts a simplified illustration of an animal cell, focusing on the endoplasmic reticulum (ER). The cell is represented as a blue circle with a darker blue outline. Inside the cell, a smaller blue circle represents the nucleus, which contains a smaller, even darker blue circle for the nucleolus. Adjacent to the nucleus is a network of interconnected, flat, sac-like structures in a deeper blue. These structures are dotted with small, even darker blue circles, representing ribosomes. A thin line connects these structures to the label \"Rough ER.\" The lighter blue space surrounding the nucleus and the ER represents the cytoplasm. The abbreviation \"ER\" is displayed in bold, large, blue letters in the bottom left corner, preceded by the word \"Abbreviation:\" in smaller font size. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_12.jpg'}, page_content='The image illustrates a simplified model of an animal cell, specifically focusing on the endoplasmic reticulum (ER). The cell is represented as a blue circle containing a smaller blue circle, the nucleus, at its center. Within the cell, surrounding the nucleus, are two distinct types of ER:\\n\\n* **Rough ER:** Depicted as a series of interconnected, flattened sacs (cisternae) studded with small black dots representing ribosomes. \\n* **Smooth ER:** Illustrated as a network of interconnected tubules lacking ribosomes, hence appearing smooth. \\n\\nThe space surrounding the nucleus and ER is the cytoplasm. Small black dots scattered throughout the cytoplasm likely represent other cellular components. The abbreviation for endoplasmic reticulum, \"ER\", is presented in bold letters at the bottom left. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_13.jpg'}, page_content='The image displays a diagram of an animal cell with a focus on the endoplasmic reticulum. \\n\\nOn the left side, there\\'s a zoomed-in depiction of the rough endoplasmic reticulum. It shows a gray chain, representing mRNA, with two attached black blobs, representing ribosomes. The mRNA chain is labeled with \"AAA\" at its end.  \\n\\nThe main part of the image shows a circular animal cell with a thin outer layer, a light blue cytoplasm, and a round nucleus in the center. Within the cytoplasm, there are two distinct types of endoplasmic reticulum depicted in blue:\\n\\n* **Rough ER:** This type encircles the nucleus and has a textured appearance due to numerous blue dots on its surface, representing ribosomes. \\n* **Smooth ER:** Located further away from the nucleus, the smooth ER is characterized by its smooth, continuous membrane without any ribosomes attached. \\n\\nLabels and captions are included in the image to identify the different components:\\n\\n* **The animal cell:** Title of the diagram.\\n* **Endoplasmic Reticulum:** Subheading indicating the focus of the diagram.\\n* **Rough ER: Protein Synthesis:** Label describing the function of the rough ER.\\n* **Abbreviation: ER:**  Clarification of the abbreviation used for the endoplasmic reticulum.\\n* **Rough ER coated with Ribosomes:** Label pointing to the rough ER within the cell.\\n* **Smooth ER:** Label pointing to the smooth ER within the cell. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_14.jpg'}, page_content='The image shows a diagram of an animal cell, focusing on the endoplasmic reticulum. The cell is represented as a blue circle with a double-lined circumference. Inside the cell, a large, circular structure occupies the center, representing the nucleus. Surrounding the nucleus are two types of endoplasmic reticulum: rough ER and smooth ER. \\n\\nThe rough ER is depicted as a series of interconnected flattened sacs, colored in a darker shade of blue, located adjacent to the nucleus. It is studded with small black dots representing ribosomes, giving it a rough appearance. The smooth ER is illustrated as a series of interconnected tubules, colored in a lighter shade of blue, extending outward from the rough ER. It lacks ribosomes, hence its smooth appearance.  \\n\\nThe image also includes labels for \"Rough ER coated with Ribosomes\" and \"Smooth ER,\" with lines pointing to the respective structures. There is also an abbreviation at the bottom left corner stating \"Abbreviation: ER\".\\n'), Document(metadata={'image_url': './video_data/video_img/frame_15.jpg'}, page_content='The image illustrates a simplified model of an animal cell with a focus on the Golgi apparatus. \\n\\nThe cell is depicted as a circular structure with a thin outer boundary representing the cell membrane. Inside, a large, circular nucleus with a smaller, filled circle inside it represents the nucleolus. Surrounding the nucleus is a cloud-like area shaded in a lighter blue, symbolizing the cytoplasm. \\n\\nTwo structures are highlighted within the cytoplasm.  Near the nucleus, a series of interconnected, blue, curved shapes with a dashed outline depict the rough endoplasmic reticulum. On the opposite side, a stack of flattened, elongated sacs colored in shades of purple represents the Golgi apparatus, labeled with a line pointing directly at it. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_16.jpg'}, page_content='The image is a simple cartoon diagram of an animal cell. The animal cell is circular with a dark blue outline and light blue interior.  There is a circular nucleus off-center with a dark blue outline, light blue interior, and a smaller, solid blue circle inside it. Around the nucleus is a blue, cloudlike structure with dashed lines emanating from it. On the periphery of the cell are two other blue structures, both composed of a series of three wavy lines. One of these structures has a line pointing to it that is labeled “Golgi”.  There are five small black dots on the bottom half of the image, inside the border of the cell.   The title at the top of the image reads “The animal cell Golgi apparatus”. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_17.jpg'}, page_content='The image illustrates an animal cell with its components labeled. A large circular light blue area represents the cytoplasm, which contains smaller components: a blue and light blue nucleus, a blue Golgi apparatus, a purplish-red Golgi apparatus, and several small black dots. A dark pink circle located near the bottom of the cell is labeled \"Lysosome\". There is also a small blue lysosome near the top of the cell. The image is titled \"The animal cell.\" \\n'), Document(metadata={'image_url': './video_data/video_img/frame_18.jpg'}, page_content='The image illustrates a simplified diagram of an animal cell.  Within the circular cell membrane, several structures are shown. A large, circular structure with multiple concentric circles is located off-center. Smaller, curved, blue structures are to the left, while a layered, pink and purple structure occupies the lower section of the cell. Two small, dark red circles represent lysosomes, with one labeled at the bottom right corner.  Additional tiny black dots are scattered throughout the cell. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_19.jpg'}, page_content='The image is a simple cartoon diagram of a round, blue animal cell. The title, \"The Animal Cell,\" is written in large, black font above the cell. Below the title is the word \"Mitochondria\" in slightly smaller blue letters. Inside the cell, there are several oblong, orange organelles with curved lines inside them.  These are labeled \"Mitochondrium\" in black text with a line pointing to one of them. Below the label is the phrase \"Powerhouse of the cell\". The nucleus of the cell is shown as two concentric blue circles, the outer ring with an irregular blue line inside, resembling a zig-zag. To the right of the nucleus is a stack of flat, purple, sac-like shapes. Below the nucleus are two long, thin blue lines with smaller lines branching off. Scattered within the cell are a few small black dots.  '), Document(metadata={'image_url': './video_data/video_img/frame_2.jpg'}, page_content='The image shows the words \"Animal Cell\" in bold, black letters at the top of the image. Centered below the text is an illustration of a petri dish containing a variety of colorful shapes. Superimposed on the petri dish is a rectangular notification box with rounded corners. It is grey with a darker grey outline. Inside, a teal circle containing a white cartoon image of a laboratory beaker is on the left. To the right of the beaker is the word \"SUBSCRIBED\" in black letters and a black outline of a bell. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_20.jpg'}, page_content='The image depicts a simplified illustration of an animal cell with various organelles labeled.\\n\\n* **Cell:** The entire structure is enclosed within a blue circle, representing the cell membrane.\\n\\n* **Nucleus:** A large, circular organelle located centrally within the cell. It has a darker blue outer circle representing the nuclear envelope, and a smaller, lighter blue circle inside representing the nucleolus.\\n\\n* **Endoplasmic Reticulum (ER):** Shown as a series of interconnected, blue, folded lines adjacent to the nucleus.\\n\\n* **Golgi Apparatus:** Illustrated as a stack of flattened, purple, sac-like structures situated near the cell membrane.\\n\\n* **Mitochondria:** Represented as a bean-shaped organelle with an inner membrane folded into cristae, depicted in a darker blue.\\n\\n* **Peroxisomes:** Depicted as small, oval-shaped organelles with a textured, orange interior. Several peroxisomes are scattered throughout the cytoplasm.\\n\\n* **Other components:**  Small, dark blue dots scattered throughout the cell represent ribosomes. A single yellow circle might be a lysosome.  A single dark red circle may be a vacuole. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_21.jpg'}, page_content='The image illustrates an animal cell with its components labeled. The cell is depicted as a circular structure, colored in light blue, with a thin outer boundary representing the cell membrane. Within the cell are various organelles, each with a distinct shape, size, and color:\\n\\n* **Peroxisome:** Circular, small organelles with an orange outline and yellow interior. One peroxisome is individually labeled outside the cell.\\n* **Nucleus:** The largest organelle, centrally located, drawn in multiple shades of blue. It has a circular shape with a smaller, fully filled blue circle inside representing the nucleolus.  A dotted line around the nucleus depicts the nuclear membrane.\\n* **Endoplasmic Reticulum (ER):** Shown as interconnected, elongated sacs and tubes in blue, situated near the nucleus. \\n* **Golgi Apparatus:** Represented as a stack of flattened, curved sacs in purple, located near the cell\\'s periphery.\\n* **Cytoplasm:** The light blue space encompassing all the organelles within the cell membrane.\\n\\nOn the right side of the image, a pie chart is partially filled with orange color, and labeled as \"H2O2.\" This likely represents the role of peroxisomes in breaking down hydrogen peroxide. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_22.jpg'}, page_content='The image is a cartoon drawing of the inside of an animal cell. The cell is a circle with a thin outline. Inside the cell, there are several different organelles, each with a distinct shape and color. These include:\\n\\n* **Cytoskeleton:**  Represented as thin, wavy lines in green, blue, and red, located near the top of the cell.\\n* **Nucleus:**  A large, circular organelle in the center with a light blue interior and a darker blue circle inside.  The darker circle represents the nucleolus.\\n* **Mitochondria:**  Orange, bean-shaped organelles scattered throughout the cell.\\n* **Endoplasmic Reticulum:**  A blue, folded structure located near the nucleus, with a rough appearance on the portion closer to the nucleus and a smooth appearance further away.\\n* **Golgi Apparatus:**  A purple, stacked structure resembling a series of flattened sacs, located near the edge of the cell. \\n* **Small, round organelles:** Represented as orange dots and a single maroon dot, scattered throughout the cytoplasm.\\n\\nThe background of the image is white, and the title \"The animal cell\" appears at the top in bold black letters, with \"Cytoskeleton\" written in a smaller font below. A thin black line extends from the word \"Cytoskeleton\" to the corresponding structure within the cell. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_23.jpg'}, page_content=\"The image depicts a cross-section of a typical animal cell with its different organelles labeled.  The cell's cytoplasm is light blue, with various organelles in different shapes and colors.\\n\\nStarting from the top, we see thin, colored, curved lines representing **Microtubules** (green), **Actin filaments** (red), and **Intermediate filaments** (purple) that make up the **cytoskeleton**.  \\n\\nMoving inward, there's a large, circular, blue **nucleus** with a darker blue, circular **nucleolus** inside. The nucleus is enclosed by a dashed blue **nuclear envelope**.\\n\\nSurrounding the nucleus is light blue **endoplasmic reticulum** (ER) with both smooth and rough variations. The rough ER is studded with small, black dots representing **ribosomes**. \\n\\nOther visible organelles include orange, bean-shaped **mitochondria**, a stack of flattened, purple sacs depicting the **Golgi apparatus**, and small, yellow **lysosomes**. Scattered black dots represent free **ribosomes** within the cytoplasm. The entire cell is enclosed by a thin, black line representing the **cell membrane**.\\n\"), Document(metadata={'image_url': './video_data/video_img/frame_24.jpg'}, page_content='The image depicts a cross-section of a generalized animal cell, focusing on the components of the cytoskeleton.  The cell has a circular shape.\\n\\n**Cytoskeleton Components:**\\n\\n* **Microtubules:**  Illustrated as thin, green, slightly curved lines near the top of the cell. \\n* **Actin Filaments:** Represented by a red line that follows the curvature of the cell membrane. \\n* **Intermediate Filaments:** Shown as a blue line with a slight wave, positioned between the microtubules and actin filaments.\\n\\n**Other Cellular Structures:**\\n\\n* **Cell Membrane:** A thin, dark blue line forming the outer boundary of the cell.\\n* **Nucleus:** A large, circular structure in the center of the cell, colored light blue with a darker blue, dashed outline. The nucleus contains two smaller, dark blue circles.\\n* **Various Organelles:**  Represented by different shapes and colors scattered throughout the cytoplasm (the area inside the cell membrane but outside the nucleus). Examples include:\\n    * Orange, bean-shaped structures with internal lines\\n    * A small, orange circle with a yellow center\\n    * A layered, purple structure resembling a stack of flattened sacs\\n    * Small, dark blue dots throughout the cytoplasm\\n\\nThe image is labeled \"The animal cell\" and \"Cytoskeleton,\" with labels pointing to the specific cytoskeletal elements. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_25.jpg'}, page_content='The image showcases a diagram of an animal cell with its components labeled. The cell is depicted as a circular structure with various organelles within it.\\n\\n- **Cell Membrane:** The outer boundary of the cell, represented by a thin, dark blue line.\\n\\n- **Cytoplasm:** The light blue fluid filling the cell, where the organelles are located.\\n\\n- **Nucleus:** A large, circular organelle in the center, containing a smaller, darker blue circle representing the nucleolus. The nucleus is enclosed by a dashed blue line representing the nuclear membrane.\\n\\n- **Endoplasmic Reticulum (ER):** A network of interconnected blue sacs and tubules extending from the nucleus.\\n\\n- **Golgi Apparatus:** A stack of flattened, purple sacs located near the cell membrane.\\n\\n- **Mitochondria:** Orange, bean-shaped organelles scattered throughout the cytoplasm.\\n\\n- **Lysosome:** A small, yellow circle within the cytoplasm.\\n\\n- **Centrosome:** A green, star-shaped structure located near the nucleus, with a line pointing to it and labeled \"Centrosome.\" Another line points to the outermost layer of the cell, also labeled \"Centrosome\". \\n'), Document(metadata={'image_url': './video_data/video_img/frame_26.jpg'}, page_content='The image displays a cross-section of an animal cell, with various organelles labeled. The cell is circular with a thin outer boundary.  Inside, a large, circular nucleus takes up a significant portion of the cell\\'s space. The nucleus is blue with a darker blue, circular structure inside. Several orange, bean-shaped objects are scattered throughout the cell. A small, green circular object is located near the center. A cluster of small, purple, elongated shapes is positioned at the bottom right. Thin, colored lines extend from the top of the cell towards the nucleus. An arrow pointing to a small, dark blue structure near the cell\\'s edge is labeled \"Centrosome.\" Another arrow, pointing to the thin lines, is also labeled \"Centrosome.\" The background is white, with the title \"The animal cell\" prominently displayed above the cell diagram. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_27.jpg'}, page_content='The image has a white background with a teal triangle on the left side. In white, the triangle contains the twitter logo followed by \"@HenriksLab\", and at the bottom of the triangle \"Special Thanks to Felix Schweitzer\". The rest of the image is white. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_3.jpg'}, page_content='The image shows the words \"Animal cell\" in black bold letters at the top. Below it is an illustration of an animal cell with a digital overlay. The overlay is a black box with rounded corners that reads \"Super Scientist\" in white text. Below that is the price \"€2.99/month\" and a blue button that reads \"Join.\" Underneath the button is the text \"Recurring Payment. Cancel at any time. Creator may update perks.\" in smaller white font.  The overlay then lists perks including \"Loyalty badges next to your name in comments and live chat\" and \"Custom emoji to use in comments and live chat\", with accompanying illustrations of each perk.  \\n'), Document(metadata={'image_url': './video_data/video_img/frame_4.jpg'}, page_content='The image illustrates an animal cell with a focus on the plasma membrane. It shows a circular shape representing the cell, colored in light blue. A slightly darker blue, thicker outline represents the plasma membrane. The text \"Plasma Membrane\" is placed above the cell and a line connects it to the membrane. A zoomed-in section on the right depicts the plasma membrane\\'s structure as a double layer of blue circles connected by thin blue lines. The text \"Outside the cell\" is positioned above this magnified view and \"Inside the cell\" below it. On the left side of the cell, the text \"Plasma Membrane\" and \"Selectively permeable\" are present. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_5.jpg'}, page_content='The image illustrates the plasma membrane of an animal cell. It depicts a circle shaded in light blue, representing the cell, enclosed by a double line, representing the plasma membrane. The plasma membrane is labeled with a line pointing to it, and the words \"selectively permeable\" are written below. The image is titled \"The animal cell\" and \"Plasma Membrane\". \\n'), Document(metadata={'image_url': './video_data/video_img/frame_6.jpg'}, page_content='The image is a simple diagram of an animal cell with the title \"The animal cell\" at the top. The cell is depicted as a circle with two concentric lines representing the plasma membrane. The space between the lines is white, and the space inside the inner line is filled with light blue, representing the cytoplasm. Lines extend outward from the diagram to labels.  The outer line is labeled \"Plasma Membrane\" in bold black text with the subtext \"Selectively permeable\" in smaller grey text underneath.  The inner line is labeled \"Cytoplasm\" in bold black text with the subtext \"Cytosol + membrane bound organelles\" in smaller grey text underneath.  There is a third label, \"Cytoplasm,\" in blue text on a white background inside the light blue cytoplasm at the top. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_7.jpg'}, page_content='The image is of a simple diagram of an animal cell with the nucleus labelled. The animal cell is depicted as a blue circle with a thicker outline. Inside the animal cell is a smaller circle representing the nucleus. The nucleus is a slightly darker shade of blue and has a dashed outline. A thin black line points from the nucleus to the label \"Nucleus\". Above the animal cell is the title \"The animal cell\" and directly above the nucleus is a second label reading \"Nucleus\". \\n'), Document(metadata={'image_url': './video_data/video_img/frame_8.jpg'}, page_content='The image is a simple cartoon diagram of an animal cell with the title \"The animal cell\". The cell is light blue and circular, outlined with a dark blue line, and contains a smaller circle within representing the nucleus. The nucleus is a slightly darker blue and outlined by a dashed line.  An arrow points to the nucleus and is labeled \"nucleus.\" There is text above the image stating \"Nucleus\" in blue text. To the left of the cell is a diagram of DNA, colored purple, with the label \"DNA\" below in pink. Above the cell to the right, there is text that reads \"What happens inside?\" in blue and \"Replication\" in grey text directly below. \\n'), Document(metadata={'image_url': './video_data/video_img/frame_9.jpg'}, page_content='The image depicts a simplified animal cell with a prominent nucleolus. The cell is represented as a large blue circle outlined in black. Inside the cell, a smaller blue circle with a dashed outline represents the nucleus. Within the nucleus, a solid blue dot represents the nucleolus. A straight line extends from the nucleolus to the right, ending with the label \"Nucleolus.\" Above the cell, the text reads \"The animal cell\" and \"Nucleolus\". \\n')]\n"
     ]
    }
   ],
   "source": [
    "images = load_docs_youtube_url(\"https://www.youtube.com/watch?v=5ugDJhmmkFM\")\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genenerate_image_summaries(img_dir):\n",
    "   img_paths = []\n",
    "   image_summaries = []\n",
    "\n",
    "\n",
    "   model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n",
    "   prompt = \"\"\"You are a curriculum instructor tasked with summarizing images for retrieval and in assisting in generating quiz questions.\\\n",
    "       These summaries will be embedded and usd ot retrieve the raw image.\\\n",
    "           Describe consisely the contents of the images and describe the characteristics of each component of the image. Do not infer what the image means unless it is for analysing mathematical graphs.\"\"\"\n",
    "\n",
    "   for filename in sorted(os.listdir(img_dir)):\n",
    "     print(filename)\n",
    "     if filename.endswith(\".jpg\"):\n",
    "       image_path = os.path.join(img_dir,filename)\n",
    "       img_paths.append(image_path)\n",
    "       img = Image.open(image_path)\n",
    "       response = model.generate_content([prompt,img])\n",
    "       image_summaries.append(response)\n",
    "   img_summaries = []\n",
    "\n",
    "#extracts only the summary text from the llm response\n",
    "   for summary in image_summaries:\n",
    "     img_summary = summary.candidates[0].content.parts[0].text\n",
    "     img_summaries.append(img_summary)\n",
    "\n",
    "\n",
    "#creates document object with image summary and image path\n",
    "   img_docs = []\n",
    "   for i in range(len(img_summaries)):\n",
    "     summary = img_summaries[i]\n",
    "     metadata = img_paths[i]\n",
    "     img_doc = Document(page_content=summary,metadata={\"image_url\":metadata})\n",
    "     img_docs.append(img_doc)\n",
    "  \n",
    "   return img_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from app.services.logger import setup_logger\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import RecognitionAudio, RecognitionConfig\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import speech_recognition as sr\n",
    "import tempfile\n",
    "import uuid\n",
    "import requests\n",
    "import gdown\n",
    "import shutil\n",
    "import io\n",
    "import os\n",
    "import base64\n",
    "def audio_to_docs(audio_dir):\n",
    "\n",
    "    \n",
    "    # Convert the MP3 file to WAV\n",
    "    try:\n",
    "        audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "        audio.export(wav_file_path, format=\"wav\")\n",
    "        if verbose:\n",
    "            logger.info(\"Conversion to WAV successful!\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to convert MP3 to WAV: {e}\")\n",
    "        raise Exception(f\"Failed to convert MP3 to WAV: {e}\")\n",
    "\n",
    "    chunk_length_ms = 60000  # 1-minute chunks\n",
    "    chunks = split_audio_fixed_intervals(audio, chunk_length_ms)\n",
    "\n",
    "    # Create a recognizer instance\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Process each chunk\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file_path = os.path.join(audio_dir, f'chunk_{i}.wav')\n",
    "        try:\n",
    "            # Export the chunk to a file\n",
    "            chunk.export(chunk_file_path, format=\"wav\")\n",
    "            logger.info(f\"Chunk file created: {chunk_file_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to export chunk {i} to file: {e}\")\n",
    "\n",
    "        try:\n",
    "            with sr.AudioFile(chunk_file_path) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                logger.info(f\"Audio data recorded for chunk {i}. Duration: {len(audio_data.frame_data) / audio_data.sample_rate:.2f} seconds\")\n",
    "\n",
    "                if len(audio_data.frame_data) == 0:\n",
    "                    logger.warning(f\"Warning: No audio data recorded for chunk {i}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Recognize speech using Google web speech API\n",
    "                    text = recognizer.recognize_google(audio_data)\n",
    "                    docs.append(Document(page_content=text))  # Create Document objects from text\n",
    "                    if verbose:\n",
    "                        logger.info(f\"Transcription for chunk {i} successful: {text}\")\n",
    "                except sr.UnknownValueError:\n",
    "                    logger.warning(f\"Chunk {i}: Google Speech Recognition could not understand the audio.\")\n",
    "                except sr.RequestError as e:\n",
    "                    logger.error(f\"Chunk {i}: Could not request results from Google Speech Recognition service: {e}\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Chunk file not found: {chunk_file_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error occurred while processing chunk {i}: {e}\")\n",
    "            raise Exception(f\"Unexpected error during chunk processing: {e}\")\n",
    "        if docs:\n",
    "         logger.info(f\"docs successfully created   , execute IF and split\")\n",
    "         split_docs = splitter.split_documents(docs)\n",
    "         logger.info(f\"after splitter ,\")\n",
    "         if verbose:\n",
    "            logger.info(\"Found transcript\")\n",
    "            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n",
    "        return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "\n",
    "#USING GOOGLE WEB SPEECH API (FREE SERVICE USED FOR WEB TRANSCRIPT)\n",
    "def generate_docs_from_audio(audio_file,audio_url: str, verbose=False):\n",
    "    if not audio_file:\n",
    "      logger.info(\"INSIDE generate_docs_from_audio\")\n",
    "      try:\n",
    "        # Attempt to create a temporary directory\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        logger.info(f\"Temporary directory created: {temp_dir}\")\n",
    "\n",
    "      except OSError as e:\n",
    "        # Handle any errors that occur while interacting with the file system\n",
    "        logger.error(f\"Failed to create temporary directory: {e}\")\n",
    "        raise Exception(f\"An error occurred while creating the temporary directory: {e}\")\n",
    "\n",
    "\n",
    "       # Generate unique file names for the MP3 and WAV files\n",
    "      mp3_audio = f'mp3_audio_{uuid.uuid4()}.mp3'\n",
    "      wav_audio = f'wav_audio_{uuid.uuid4()}.wav'\n",
    "      wav_file_path = os.path.join(temp_dir, wav_audio)\n",
    "    \n",
    "      docs = []\n",
    "\n",
    "      # Download the file from the URL and save it to a temporary file\n",
    "      try:\n",
    "        response = requests.get(audio_url)\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "      except (requests.exceptions.RequestException) as req_err:\n",
    "        logger.error(f\"Error occurred while downloading audio: {req_err}\")\n",
    "        raise Exception(f\"Error occurred while downloading audio: {req_err}\")\n",
    "\n",
    "      with tempfile.NamedTemporaryFile(delete=False, prefix=mp3_audio) as temp_file:\n",
    "        temp_file.write(response.content)\n",
    "        mp3_file_path = temp_file.name\n",
    "        logger.info(f\"mp3_file_path: {mp3_file_path}\")\n",
    "    else:\n",
    "        mp3_file_path = audio_file\n",
    "\n",
    "    # Convert the MP3 file to WAV\n",
    "    try:\n",
    "        audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "        audio.export(wav_file_path, format=\"wav\")\n",
    "        if verbose:\n",
    "            logger.info(\"Conversion to WAV successful!\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to convert MP3 to WAV: {e}\")\n",
    "        raise Exception(f\"Failed to convert MP3 to WAV: {e}\")\n",
    "\n",
    "\n",
    "    # Split WAV file into smaller chunks\n",
    "    chunk_length_ms = 60000  # 1-minute chunks\n",
    "    chunks = split_audio_fixed_intervals(audio, chunk_length_ms)\n",
    "\n",
    "    # Create a recognizer instance\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Process each chunk\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file_path = os.path.join(temp_dir, f'chunk_{i}.wav')\n",
    "        try:\n",
    "            # Export the chunk to a file\n",
    "            chunk.export(chunk_file_path, format=\"wav\")\n",
    "            logger.info(f\"Chunk file created: {chunk_file_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to export chunk {i} to file: {e}\")\n",
    "\n",
    "        try:\n",
    "            with sr.AudioFile(chunk_file_path) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                logger.info(f\"Audio data recorded for chunk {i}. Duration: {len(audio_data.frame_data) / audio_data.sample_rate:.2f} seconds\")\n",
    "\n",
    "                if len(audio_data.frame_data) == 0:\n",
    "                    logger.warning(f\"Warning: No audio data recorded for chunk {i}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Recognize speech using Google web speech API\n",
    "                    text = recognizer.recognize_google(audio_data)\n",
    "                    docs.append(Document(page_content=text))  # Create Document objects from text\n",
    "                    if verbose:\n",
    "                        logger.info(f\"Transcription for chunk {i} successful: {text}\")\n",
    "                except sr.UnknownValueError:\n",
    "                    logger.warning(f\"Chunk {i}: Google Speech Recognition could not understand the audio.\")\n",
    "                except sr.RequestError as e:\n",
    "                    logger.error(f\"Chunk {i}: Could not request results from Google Speech Recognition service: {e}\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Chunk file not found: {chunk_file_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error occurred while processing chunk {i}: {e}\")\n",
    "            raise Exception(f\"Unexpected error during chunk processing: {e}\")\n",
    "\n",
    "    # Clean up temporary files\n",
    "    try:    \n",
    "        if os.path.exists(wav_file_path):\n",
    "            os.remove(wav_file_path)\n",
    "            if verbose:\n",
    "                logger.info(f\"Temporary WAV file {wav_file_path} deleted.\")\n",
    "        if os.path.exists(mp3_file_path):\n",
    "            os.remove(mp3_file_path)\n",
    "            if verbose:\n",
    "                logger.info(f\"Temporary MP3 file {mp3_audio} deleted.\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        if verbose:\n",
    "            logger.info(\"Temporary directory deleted.\")\n",
    "    \n",
    "    except OSError as e:\n",
    "        logger.error(f\"Error during cleanup temporary files: {e}\")\n",
    "        if verbose:\n",
    "            logger.info(f\"Error during cleanup: {e}\")\n",
    "\n",
    "    if docs:\n",
    "        logger.info(f\"docs successfully created   , execute IF and split\")\n",
    "        split_docs = splitter.split_documents(docs)\n",
    "        logger.info(f\"after splitter ,\")\n",
    "        if verbose:\n",
    "            logger.info(\"Found transcript\")\n",
    "            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n",
    "        return split_docs\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "# Retrieve the API key from environment variables\n",
    "GOOGLE_CLOUD_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "if not GOOGLE_CLOUD_API_KEY:\n",
    "    raise ValueError(\"API key not found. Please check your .env file.\")\n",
    "\n",
    "GOOGLE_CLOUD_SPEECH_TO_TEXT_URL = os.getenv('GOOGLE_SPEECH_URL')\n",
    "if not GOOGLE_CLOUD_SPEECH_TO_TEXT_URL:\n",
    "    raise ValueError(\"GOOGLE_CLOUD_SPEECH_TO_TEXT_URL not found. Please check your .env file.\")\n",
    "\n",
    "#USING GOOGLE SPEECH-TO-TEXT API (PAID SERVICE)(RECOMMENDED FOR LARGE AUDIO FILES)\n",
    "def generate_docs_from_audio_gcloud(audio_url: str, lang: str, verbose=False):\n",
    "    logger.info(\"INSIDE generate_docs_from_audio_gcloud\")\n",
    "    try:\n",
    "        # Attempt to create a temporary directory\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        logger.info(f\"Temporary directory created: {temp_dir}\")\n",
    "\n",
    "    except OSError as e:\n",
    "        # Handle any errors that occur while interacting with the file system\n",
    "        logger.error(f\"Failed to create temporary directory: {e}\")\n",
    "        raise Exception(f\"An error occurred while creating the temporary directory: {e}\")\n",
    "    \n",
    "\n",
    "    # Generate unique file names for the MP3 and WAV files\n",
    "    mp3_audio = f'mp3_audio_{uuid.uuid4()}.mp3'\n",
    "    wav_audio = f'wav_audio_{uuid.uuid4()}.wav'\n",
    "    wav_file_path = os.path.join(temp_dir, wav_audio)\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    # Download the file from the URL and save it to a temporary file\n",
    "    try:\n",
    "        response = requests.get(audio_url)\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "    except (requests.exceptions.RequestException) as req_err:\n",
    "        logger.error(f\"Error occurred while downloading audio: {req_err}\")\n",
    "        raise Exception(f\"Error occurred while downloading audio: {req_err}\")\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, prefix=mp3_audio) as temp_file:\n",
    "        temp_file.write(response.content)\n",
    "        mp3_file_path = temp_file.name\n",
    "        logger.info(f\"mp3_file_path: {mp3_file_path}\")\n",
    "\n",
    "    # Convert the MP3 file to WAV\n",
    "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "    audio.export(wav_file_path, format=\"wav\")\n",
    "    if verbose:\n",
    "        logger.info(\"Conversion to WAV successful!\")\n",
    "\n",
    "    # Split WAV file into smaller chunks with a slightly reduced length to avoid exceeding the limit\n",
    "    chunk_length_ms = 59000  # 59 seconds to ensure it's under the 1-minute limit for the API\n",
    "    chunks = split_audio_fixed_intervals(audio, chunk_length_ms)\n",
    "\n",
    "\n",
    "    # Google Cloud Speech-to-Text API URL\n",
    "    url = GOOGLE_CLOUD_SPEECH_TO_TEXT_URL\n",
    "\n",
    "    # Process each chunk\n",
    "    for i, chunk in enumerate(chunks): \n",
    "        chunk_file_path = os.path.join(temp_dir, f'chunk_{i}.wav')\n",
    "        try:\n",
    "            # Export the chunk to a file\n",
    "            chunk.export(chunk_file_path, format=\"wav\")\n",
    "            logger.info(f\"Chunk file created: {chunk_file_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to export chunk {i} to file: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # Load the audio data and encode it in base64\n",
    "            with open(chunk_file_path, \"rb\") as audio_file:\n",
    "                content = base64.b64encode(audio_file.read()).decode('utf-8')\n",
    "\n",
    "            headers = {\n",
    "                'Content-Type': 'application/json',\n",
    "            }\n",
    "\n",
    "            params = {\n",
    "                'key': GOOGLE_CLOUD_API_KEY,\n",
    "            }\n",
    "\n",
    "            data = {\n",
    "                \"config\": {\n",
    "                    \"encoding\": \"LINEAR16\",\n",
    "                    \n",
    "                    \"languageCode\": lang,\n",
    "                },\n",
    "                \"audio\": {\n",
    "                    \"content\": content\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Send the request to the Speech-to-Text API\n",
    "            try:\n",
    "                response = requests.post(url, headers=headers, params=params, json=data)\n",
    "                response.raise_for_status()\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logger.error(f\"API request failed for chunk {i}: {e}\")\n",
    "                logger.error(f\"Response content: {response.content}\")\n",
    "                continue\n",
    "\n",
    "            # Process the response\n",
    "            result = response.json()\n",
    "            for result in result.get('results', []):\n",
    "                text = result['alternatives'][0]['transcript']\n",
    "                docs.append(Document(page_content=text))\n",
    "            if verbose:\n",
    "                logger.info(f\"Transcription for chunk {i} successful: {text}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Chunk file not found: {chunk_file_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error occurred while processing chunk {i}: {e}\")\n",
    "            raise Exception(f\"Unexpected error during chunk processing: {e}\")\n",
    "\n",
    "\n",
    "   # Clean up temporary files\n",
    "    try:    \n",
    "        if os.path.exists(wav_file_path):\n",
    "            os.remove(wav_file_path)\n",
    "            if verbose:\n",
    "                logger.info(f\"Temporary WAV file {wav_file_path} deleted.\")\n",
    "        if os.path.exists(mp3_file_path):\n",
    "            os.remove(mp3_file_path)\n",
    "            if verbose:\n",
    "                logger.info(f\"Temporary MP3 file {mp3_audio} deleted.\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        if verbose:\n",
    "            logger.info(\"Temporary directory deleted.\")\n",
    "    \n",
    "    except OSError as e:\n",
    "        logger.error(f\"Error during cleanup temporary files: {e}\")\n",
    "        if verbose:\n",
    "            logger.info(f\"Error during cleanup: {e}\")\n",
    "\n",
    "    if docs:\n",
    "        logger.info(f\"docs successfully created   , execute IF and split\")\n",
    "        split_docs = splitter.split_documents(docs)\n",
    "        logger.info(f\"after splitter ,\")\n",
    "        if verbose:\n",
    "            logger.info(\"Found transcript\")\n",
    "            logger.info(f\"Splitting documents into {len(split_docs)} chunks\")\n",
    "        return split_docs\n",
    "\n",
    "\n",
    "\n",
    "def split_audio_fixed_intervals(audio: AudioSegment, interval_ms: int):\n",
    "    \"\"\"\n",
    "    Split audio into chunks of fixed length.\n",
    "\n",
    "    Args:\n",
    "        audio (AudioSegment): The audio segment to split.\n",
    "        interval_ms (int): The length of each chunk in milliseconds.\n",
    "\n",
    "    Returns:\n",
    "        List[AudioSegment]: List of audio chunks.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    length_ms = len(audio)\n",
    "\n",
    "    # Split the audio into chunks\n",
    "    for start in range(0, length_ms, interval_ms):\n",
    "        end = min(start + interval_ms, length_ms)\n",
    "        chunk = audio[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # Verify the length of each chunk\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        logger.info(f\"Chunk {i} length: {len(chunk)} ms\")\n",
    "        if len(chunk) >= interval_ms:\n",
    "            logger.info(f\"Warning: Chunk {i} is very close or exceeds the limit of {interval_ms} ms.\")\n",
    "\n",
    "    return chunks\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "import ssl\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "def load_docs_youtube_url(youtube_url: str, verbose=True) -> str:\n",
    "    loader = YoutubeLoader.from_youtube_url(youtube_url, add_video_info=True)\n",
    "    docs = loader.load()\n",
    "    length = docs[0].metadata[\"length\"]\n",
    "    title = docs[0].metadata[\"title\"]\n",
    "        \n",
    "    split_docs = splitter.split_documents(docs)\n",
    "\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"hello guys welcome back to the channel for another Azure video today's video will be a bit different what I mean by that it would be easier and more fun we are going to use the pi tube library in order to convert a YouTube video into an MP3 file and we are going to use the flask framework you know the famous flask framework and host a web application on azure I wanted to download the podcast with Lex Fremont and that youtuberman the other day and that's how I came up with the idea of course there are plenty of websites that convert YouTube videos into MP3 files but you know you have to click one million buttons and pop-ups to download the file so I thought it must be a better way and an easier way using Python and there is this pipecube Library so with this Library we can download the video or we can download only the audio of the video in our case we've gone to only the audio but we are going to see both cases then we are going to use a very simple flask template provided on Azure\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"are going to see both cases then we are going to use a very simple flask template provided on Azure documentation to host a web app on Azure we are going to provide the video URL and it will give us back the MP3 file in other words we are going to create a web app and host it on Azure which is quite easy and fun and entertaining let's get down to the nitty gritty the first step is to actually search a quick start you know tutorial of how to deploy a python web app to Azure app service this webpage will come up and if you go if you scroll down you will see a sample application on GitHub provided by Microsoft so download this on your local machine download the application the code from GitHub and open up.py and it will you will see this code here which is a very basic flask application that has a four that renders an HTML with a form you provide the name and it displays your name back right so let's run this and see what we get and follow this link here on your Local Host this is the\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"so let's run this and see what we get and follow this link here on your Local Host this is the web app so if you type you know your name click on say hello and it will give you that result here hello it's nice to meet you and that is it okay so we have this web app now it's time to use our pythube library in order to convert YouTube videos into MP3 files the first thing we need to do is import the pi tube library from PI tube import YouTube right and then we also need the white huge progress bar so from PI tube dot CLI right import on progress and this will display display a progress bar when you download the video and the last thing we need to import is pi tube dot exceptions import that generic by Cube Arrow of course if you're going to requirements.txt we need to actually uh place here by Cube as well in the requirements let's go back into our application and now here under slash hello where we receive the name that we placed on the form in the HTML page before here we are going to\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"where we receive the name that we placed on the form in the HTML page before here we are going to write our code and let's create a YouTube object and we can do that by using YouTube and here we need to provide a link so what would be the link for the time being let's uh use a just use a static link let me get one that's a link from one of my YouTube videos right so here we provide the link and then we can also use on Pro progress callback or you can use some complete callback whatever you like then on progress which is the one that we imported from the pi tube CLI right perfect and this will display a progress bar when you download a video into your command line if it takes long enough of course the next thing we need to do is actually display the streams from this YouTube object let me switch to Pi tube documentation so you can get an idea of what we are talking about here you can see all the steps of how to install Pi tube pip install Pi tube of course you can check the source code\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"all the steps of how to install Pi tube pip install Pi tube of course you can check the source code there is a quick start demo here of how to create uh you know how to use spycube of course as we already saw from patio we have to import the YouTube object provide a link and it has all those uh you know properties here on progress callback or on complete callback etc etc and then we need to work with the streams so there are progressive streams and thus streams if you notice there are some streams listed that have both a video call Deck and the audio code deck While others just have video or just audio this is the this is a result of YouTube supporting a streaming technique called Das so now if you uh if you want the highest quality stream you have to download separately you know the video and separately uh the audio and then comments them using uh software like ffmpeg right but uh we're not going to do that we are going to get the highest resolution video and that would be with audio\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"not going to do that we are going to get the highest resolution video and that would be with audio all together with food without you uh 720 uh P resolution okay so now let's display the YouTube streams from our YouTube object so we can do that by using dot streams here we are and you we can run the web app follow the localhost just provide the whatever name you want click on say hello and let's wait for the video to get the results and here as you can see right we have all those options uh the video slash MP4 the resolution if gas the code deck etc etc you consider multiple versions of resolution and we can also have the audio type separately if you want to download the video it's very easy so there are plenty of options to choose the stream you want by using the itag or for example Buy filtering right you can filter and click on Progressive let's say true or false whatever you want if you want the highest uh resolution without the audio so click on two type A2 and then click on the\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"you want the highest uh resolution without the audio so click on two type A2 and then click on the order by resolution foreign ER and select the first one so this would give you and then actually uh dot download and this will download the video in your local uh in your local directory but it would be only the video with the highest resolution but without audio if so if you go on the video uh with the audio and that has the highest resolution you don't have to do all that you can click on get get highest resolution and Dot download right and if you do that it's going to download this stream that is about uh 720 resolution and an mp4 file type into your local directory and that's it so you will have the whole video but in our case we want only the audio how can we do that so let's uh no that would be audio in this case so that would be equals the YouTube dot streams and then we need to filter and select the audio only audio to and then order by let's say if we want to order by uh let's\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"and select the audio only audio to and then order by let's say if we want to order by uh let's use for example KBR to order by APR attribute and then order buys and use uh descending order right and Dot first and then we can use audio don't download and that will download the video in our local directory let's remove that print statement here and we can run the code that actually see the audio right so let's run the code again follow the link to your local host click on say hello and let's wait for the video to be downloaded you see here we have this uh video downloaded it's a webm file and it's only the audio so if you click that it will only give you the audio right this is how easy it is right to download the video or if you want the audio download the audio only but we won't actually we have a web app so we want to download to actually to return a file an audio file to the users for them to download how can we do that so we don't have to store the whole video locally or you know\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"them to download how can we do that so we don't have to store the whole video locally or you know in Azure in a database or whatever in the blob storage and then uh pick it up again and give it to the user we can create binary stream of in-memory data using the i o Library so in from IO import bytes IO that's how you create a binary stream uh in memory binary stream and what we have an option here right so let's create a buffer and that would be bytes IO let's create an object a buffer and here what we have to do is click on audio and then if you scroll down it will you will see an option which says stream to buffer perfect fly right it fits us perfectly so provide the buffer here and let now this would this audio will be streamed to the buffer and of course now the buffer the position of the buffer is at the end we want it to go again uh in the beginning to the beginning so what we have to do here is type buffer.c and position zero to go back to the beginning of the Stream because\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"to do here is type buffer.c and position zero to go back to the beginning of the Stream because now we're going to send back this buffer which is a binary stream of data or our audio file in this case and we have to use from flask uh type one more thing and that would be send file right so here instead delete that and now we need to return to this file this buffer as a file this binary stream of audio as a file let's return click on send file now let's provide the parameters that would be the buffer itself buffer comma answer attachment file as a touch uh so as attachment that's true then we got attachment file name now this is important because actually you remember uh remember before that we we check the file that we downloaded the audio was of extension webm but we want extension MP3 so we have to rename the file how can we get the title of the file that's easy so here audio dot title very very convenient everything is provided for us dot MP3 pretty easy right comma meme type and\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"very very convenient everything is provided for us dot MP3 pretty easy right comma meme type and then let's say audio slash MP3 that's fine we are going to return so this stream this binary stream as a file to the user what else is left I think we need to use a try and cut statement here if the video fails to be you know like if we fail to download the video so accept come on buy two error print or raise or whatever you want or pass Arrow here and then we return the audio stream as a file so let's change that to URL because right the user will provide the video URL on our HTML form and we are going to get it here this video URL and instead of this link which is a static link we are going to use URL here and convert the video that the user requested right perfect let's go into our templates here let's change the labels so here instead of that please provide URL to convert and instead of say hello just type convert and I think we are good to go so let's run the code and see what happens\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"hello just type convert and I think we are good to go so let's run the code and see what happens follow the link on your local machine here is our web application so now the user has to provide a video URL to convert from YouTube let's provide this one click on convert and now we expect to download the audio file a converted You Know audio file from the video let's see what happens the video has converted successfully going to your downloads folder and you will see the MP3 file there our web application is ready so what's the next step the next step is to host this web app on Azure how can we do that let's see first we need to install an extension Azure app Services extension search for that and here where it says Azure up service install the extension and then go to your azure environment and click on this globe here where it says Azure app service click on that click on create new web app provide a name like apple like uh web app demo or something like that click on that then select\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"app provide a name like apple like uh web app demo or something like that click on that then select the resource Group click on the research group that you have already on Azure the runtime stack at least python 3.9 for me create a new service app service plan the same name and select here the free tier of course we don't need application insights right now so we skip that step and as you can see we are deploying our web app to Azure we are creating the web app and then we are going to deploy the code right so it will take a few minutes so the web app has been created successfully now it's time to deploy our code so click on that log here Azure web services click on deploy web app select the folder that you host the application then select the web app that we just created and then deploy click on deploy and in a few minutes it will be deployed you can check the output window here to see the results and when it's ready you can browse on the internet and find your web app and yeah as\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"the results and when it's ready you can browse on the internet and find your web app and yeah as you can see here we have already hosted our web app on azure you can see the domain here it's not our localhost is uh the Azure Services app services here we have hosted our web app we can provide the URL click on convert and it's going to download as you can see the file uh in your download folder as you just witnessed is very it's very easy to create a web app and host it on azure and it's also very easy to you know convert YouTube videos get uh statistics get all those you know titles and that kind of stuff from using the bytecube library with just a few lines of code we were able to do all those things like you know create download uh and convert a YouTube video with we didn't even have to you know save the video to store the video somewhere and then uh pick it up again and give it to the user we just used a buffer and it was so easy to change the extension right it just with a few\"),\n",
       " Document(metadata={'source': 'Y_GDUc2GsGk', 'title': 'Python - Download & Convert YouTube videos into MP3/MP4 for FREE- Host Web Applications on Azure', 'description': 'Unknown', 'view_count': 2589, 'thumbnail_url': 'https://i.ytimg.com/vi/Y_GDUc2GsGk/hq720.jpg', 'publish_date': '2023-08-26 00:00:00', 'length': 1187, 'author': 'Apostolos Athanasiou'}, page_content=\"the user we just used a buffer and it was so easy to change the extension right it just with a few lines of code and you know like uh the flask application that was provided on Azure documentation we created a web app that we hosted on Azure and it's so easy to do that right now you know no you don't we don't have to handle any infrastructure or anything like that straight into coding then we deploy the app and that's it I really like it this is it guys I hope you enjoyed the video if you like the video please click the like button leave a comment and subscribe to the channel and I will see you in the next one thank you\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_docs_youtube_url(\"https://www.youtube.com/watch?v=Y_GDUc2GsGk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 1] Operation not permitted: './video_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./video_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: './video_data'"
     ]
    }
   ],
   "source": [
    "\n",
    "os.remove(\"./video_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727004090.074152 1334212 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1727004090.077782 1334212 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from PIL import Image\n",
    "llm_for_img = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",api_key=\"AIzaSyC8nSuZBgtQcqP7m1Squ836YqKJP-RxpNc\")\n",
    "def generate_docs_from_img(img_file_path,img_url=\"\", verbose: bool=False):\n",
    "    message = \"\"\n",
    "    image_summaries = []\n",
    "    if img_file_path:\n",
    "        img = Image.open(img_file_path)\n",
    "        message = message = HumanMessage(\n",
    "    content=[\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Give me a summary of what you see in the image. It must be 3 detailed paragraphs.\",\n",
    "            }, \n",
    "            {\"type\": \"image_url\", \"image\": img},\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "\n",
    "    response = llm_for_img.invoke([message]).content\n",
    "    docs = Document(page_content=response, metadata={\"source\": img_url})\n",
    "    split_docs = splitter.split_documents([docs])\n",
    "\n",
    "    return split_docs\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image_url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_docs_from_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/video_data/video_img/frame_0.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 21\u001b[0m, in \u001b[0;36mgenerate_docs_from_img\u001b[0;34m(img_file_path, img_url, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_file_path)\n\u001b[1;32m     10\u001b[0m     message \u001b[38;5;241m=\u001b[39m message \u001b[38;5;241m=\u001b[39m HumanMessage(\n\u001b[1;32m     11\u001b[0m content\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     12\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     ]\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_for_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     22\u001b[0m docs \u001b[38;5;241m=\u001b[39m Document(page_content\u001b[38;5;241m=\u001b[39mresponse, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: img_url})\n\u001b[1;32m     23\u001b[0m split_docs \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit_documents([docs])\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:276\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    272\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    273\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    275\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    286\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    770\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    774\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    775\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    632\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    634\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    635\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    637\u001b[0m ]\n\u001b[1;32m    638\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:623\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    622\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 623\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m         )\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:845\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 845\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    849\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:966\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    955\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    965\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m--> 966\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[1;32m    976\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    978\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[1;32m    979\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:1132\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._prepare_request\u001b[0;34m(self, messages, stop, tools, functions, safety_settings, tool_config, generation_config)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m functions:\n\u001b[1;32m   1130\u001b[0m     formatted_tools \u001b[38;5;241m=\u001b[39m [convert_to_genai_function_declarations(functions)]\n\u001b[0;32m-> 1132\u001b[0m system_instruction, history \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_chat_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_system_message_to_human\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_system_message_to_human\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m formatted_tool_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tool_config:\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:403\u001b[0m, in \u001b[0;36m_parse_chat_history\u001b[0;34m(input_messages, convert_system_message_to_human)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, HumanMessage):\n\u001b[1;32m    402\u001b[0m     role \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 403\u001b[0m     parts \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_to_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m convert_system_message_to_human \u001b[38;5;129;01mand\u001b[39;00m system_instruction:\n\u001b[1;32m    405\u001b[0m         parts \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m system_instruction\u001b[38;5;241m.\u001b[39mparts] \u001b[38;5;241m+\u001b[39m parts\n",
      "File \u001b[0;32m~/projects AI/kai-ai-backend/env/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:323\u001b[0m, in \u001b[0;36m_convert_to_parts\u001b[0;34m(raw_content)\u001b[0m\n\u001b[1;32m    321\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(Part(text\u001b[38;5;241m=\u001b[39mpart[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m part[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     img_url \u001b[38;5;241m=\u001b[39m \u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img_url, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m img_url:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_url'"
     ]
    }
   ],
   "source": [
    "generate_docs_from_img(img_file_path=\"/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/video_data/video_img/frame_0.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "from typing import Any\n",
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from PIL import Image\n",
    "import ssl\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyC8nSuZBgtQcqP7m1Squ836YqKJP-RxpNc\")\n",
    "def genenerate_image_summaries(img_dir):\n",
    "   \n",
    "   img_docs = []\n",
    "\n",
    "   model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")\n",
    "   prompt = \"\"\"You are a curriculum instructor tasked with summarizing images for retrieval and in assisting in generating quiz questions.\\\n",
    "       These summaries will be embedded and usd ot retrieve the raw image.\\\n",
    "           Describe consisely the contents of the images and describe the characteristics of each component of the image. Do not infer what the image means unless it is for analysing mathematical graphs.\"\"\"\n",
    "\n",
    "   for filename in sorted(os.listdir(img_dir)):\n",
    "     print(filename)\n",
    "     if filename.endswith(\".jpg\"):\n",
    "       image_path = os.path.join(img_dir,filename)\n",
    "       img = Image.open(image_path)\n",
    "       response = model.generate_content([prompt,img])\n",
    "       image_summary = response.candidates[0].content.parts[0].text\n",
    "\n",
    "       img_doc = Document(page_content=image_summary,metadata={\"image_url\":image_path})\n",
    "       img_docs.append(img_doc)\n",
    "  \n",
    "   return img_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure-1-1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727006238.619798 1334212 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure-1-2.jpg\n",
      "figure-1-3.jpg\n",
      "figure-1-4.jpg\n",
      "figure-1-5.jpg\n",
      "figure-10-16.jpg\n",
      "figure-12-17.jpg\n",
      "figure-12-18.jpg\n",
      "figure-12-19.jpg\n",
      "figure-13-20.jpg\n",
      "figure-13-21.jpg\n",
      "figure-13-22.jpg\n",
      "figure-13-23.jpg\n",
      "figure-14-24.jpg\n",
      "figure-14-25.jpg\n",
      "figure-14-26.jpg\n",
      "figure-14-27.jpg\n",
      "figure-14-28.jpg\n",
      "figure-14-29.jpg\n",
      "figure-14-30.jpg\n",
      "figure-14-31.jpg\n",
      "figure-14-32.jpg\n",
      "figure-14-33.jpg\n",
      "figure-14-34.jpg\n",
      "figure-14-35.jpg\n",
      "figure-14-36.jpg\n",
      "figure-14-37.jpg\n",
      "figure-14-38.jpg\n",
      "figure-16-39.jpg\n",
      "figure-17-40.jpg\n",
      "figure-17-41.jpg\n",
      "figure-17-42.jpg\n",
      "figure-19-43.jpg\n",
      "figure-19-44.jpg\n",
      "figure-19-45.jpg\n",
      "figure-2-1.jpg\n",
      "figure-2-2.jpg\n",
      "figure-2-6.jpg\n",
      "figure-2-7.jpg\n",
      "figure-20-46.jpg\n",
      "figure-20-47.jpg\n",
      "figure-20-48.jpg\n",
      "figure-20-49.jpg\n",
      "figure-24-50.jpg\n",
      "figure-25-51.jpg\n",
      "figure-25-52.jpg\n",
      "figure-26-53.jpg\n",
      "figure-3-3.jpg\n",
      "figure-4-10.jpg\n",
      "figure-4-11.jpg\n",
      "figure-4-8.jpg\n",
      "figure-4-9.jpg\n",
      "figure-7-12.jpg\n",
      "figure-7-13.jpg\n",
      "figure-8-14.jpg\n",
      "figure-8-15.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-1-1.jpg'}, page_content='The image is a diagram of a bacteria cell with labeled components.  There are 10 labels on the diagram. \\n\\n- **The cell surface membrane:**  A thin,  black line around the edge of the cell. \\n- **The cell wall:**  A slightly thicker black line around the cell membrane.\\n- **The nucleoid:** An irregular pink shape. \\n- **The flagellum:** A long orange structure.\\n- **The mesosome:**  A small, irregular black shape.\\n- **The small ribosomes:**  Numerous,  tiny black dots.\\n- **The plasmids:** Tiny, dark brown dots.\\n- **The photosynthetic membranes:**  Two, round, white shapes. \\n- **The glycogen granules, lipid droplets:**  A small, clustered group of  black dots. \\n- **The *:** An asterisk that indicates \"not present in all bacteria.\"'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-1-2.jpg'}, page_content=\"The image shows a diagram of two types of cells. The top image is a labelled diagram of an animal cell, showing the following components:\\n\\n* Golgi Apparatus (labelled): stacked, flattened sacs, with small vesicles budding off\\n* Secretory vesicles (labelled): small, spherical sacs \\n* Lysosome (labelled): a small, circular organelle with a denser centre \\n* Cytoplasm (labelled): a pale, yellow, gel-like substance within the cell \\n* Rough endoplasmic reticulum (labelled): network of interconnected sacs studded with ribosomes \\n* Peroxisome (labelled): a small, circular organelle with a darker centre\\n* Nucleus (labelled): a large, circular organelle, surrounded by a double membrane, containing a dark nucleolus \\n* Centriole (labelled): a pair of cylindrical structures\\n* Mitochondria (labelled): oval shaped with inner folded membranes\\n* Ribosomes (labelled): small dots scattered around the cell. \\n\\nThe bottom image is a labelled diagram of a plant cell, showing the following components: \\n\\n* Tonoplast (labelled): a thin membrane that surrounds the vacuole\\n* Vacuole (labelled): a large, circular organelle that takes up most of the cell's volume\\n* Mitochondrion (labelled): oval shaped with inner folded membranes\\n* Chloroplast (labelled): oval shaped, containing stacks of green thylakoids\\n* Nucleolus (labelled): a dark, circular organelle within the nucleus\\n* Nucleus (labelled): a large, circular organelle, surrounded by a double membrane, containing a dark nucleolus\\n* Cell wall (labelled): a thick, rigid layer surrounding the cell, with the cell surface membrane underneath. \\n\"),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-1-3.jpg'}, page_content=\"The image is a diagram of a eukaryotic cell. The cell is surrounded by a plasma membrane and contains various organelles. \\n\\nThe largest organelle is the nucleus, which is located in the center of the cell and contains the cell's genetic material. \\n\\nThe nucleus is surrounded by the endoplasmic reticulum, which is a network of membranes that is involved in protein synthesis and lipid metabolism. The endoplasmic reticulum can be either rough or smooth. The rough endoplasmic reticulum has ribosomes attached to it and is responsible for protein synthesis, while the smooth endoplasmic reticulum does not have ribosomes and is involved in lipid metabolism.\\n\\nOther organelles include the Golgi apparatus, which is a stack of flattened sacs involved in packaging and sorting proteins; the lysosomes, which are small organelles containing enzymes that break down waste materials; the mitochondria, which are responsible for energy production; the peroxisomes, which are small organelles that contain enzymes that break down fatty acids and other molecules; and the centrioles, which are small, cylindrical structures that are involved in cell division.\\n\\nThe cytoplasm is the gel-like substance that fills the cell and contains the organelles.\\n\\nThe image is labeled with the names of each organelle. \\n\"),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-1-4.jpg'}, page_content='The image is a diagram of a plant cell. The cell wall is a thick green outline around the cell. The cell membrane is a blue outline inside the cell wall. The nucleus is a large purple shape in the center of the cell. The nucleolus is a smaller purple shape within the nucleus. The cytoplasm is the light green area that surrounds the nucleus. The vacuole is a large yellow shape near the top of the cell. The tonoplast is a blue line around the vacuole. The chloroplasts are green ovals with dark green lines inside, and they are scattered throughout the cytoplasm. The mitochondria are orange shapes with internal ridges, scattered throughout the cytoplasm.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-1-5.jpg'}, page_content='The image is a diagram of a plant cell. The cell is rectangular with a cell wall outlined in brown and a cell membrane outlined in green.  The inside of the cell is filled with a light grey area, cytoplasm. Scattered within the cytoplasm are circular, green objects called chloroplasts. Two pink starch grains are present within the cytoplasm. A large, grey, circular sap vacuole is present in the center of the cell.  A round, purple structure representing the nucleus is present in the bottom of the cell.  There is a scale bar at the bottom of the image with a value of 10 micrometers.  To the right of the image are the labelled components of the cell: Numerous chloroplasts, tonoplast (membrane around vacuole), starch grain, cell wall (cell surface membrane underneath wall), sap vacuole, nucleus, and cytoplasm. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-10-16.jpg'}, page_content='The image depicts a cell in a solution. The cell is outlined with a grey line, the solute X are represented by black circles, and the solute Y are represented by white circles.  The left image shows the initial concentration of solute X and Y, and the right image shows the concentration after 30 minutes. The text \"Initial concentration\" appears below the left image, and the text \"After 30 minutes\" appears below the right image.  The image is labelled, and the label is shown on the right-hand side of the images. The labels are \"solute X\", \"cell\" and \"solute Y\".  The solute X are outside the cell, the solute Y are inside the cell.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-12-17.jpg'}, page_content=\"The image depicts the process of protein synthesis.\\n\\nThe first image shows a nucleus and the cytoplasm, with a pink circle representing the nucleus and a yellow circle representing the cytoplasm.  Inside the pink circle is a double helix labelled DNA, a gene region is labelled and a downward arrow points to a smaller molecule, mRNA, in a lighter pink colour.  A label next to the mRNA states 'double helix unravels'.  \\n\\nThe second image shows a ribosome engulfing a piece of mRNA.  There are three codons on the mRNA, coloured blue, red, and green.  The third image shows the DNA being transcribed to give a length of mRNA, the mRNA is labelled with a blue, red, and green segment.   The fourth image shows a tRNA molecule carrying an amino acid lines up against the mRNA.  There are three tRNA molecules each carrying a different amino acid.  The fifth image shows the amino acids attaching to specific tRNA.  \\n\\nThe sixth image shows the polypeptide chain of amino acids, each one being labelled aa1, aa2 etc.  The amino acids are linked to form a polypeptide chain, and there is a label stating 'peptide link formed'.\\n\\nThe final image shows the polypeptide chain being released into the cytoplasm.  The tRNA units unbind and return to the cytoplasm, and the ribosome may read the mRNA again.\"),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-12-18.jpg'}, page_content='The image contains a chain of six amino acids. The chain is curved and has six different colored blocks. The blocks are labeled with the amino acids: cysteine, alanine, lysine, glycine, leucine. The bottom of the image contains the text \"Primary structure - the linear sequence of amino acids in a peptide\".'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-12-19.jpg'}, page_content='The image depicts different levels of protein structure with accompanying text descriptions. \\n\\nAt the top, on the left, a 3D structure of a coiled spring. The spring is gray and white, composed of multiple loops of the spring that extend vertically from the top to the bottom. The spring is in a helix shape. To the right of the spring, three layers of alternating brown and yellow zig-zag shaped structures are displayed. The zig-zag shapes are composed of short, straight lines that join together to form a single shape. The shape is repeated to form three layers, with each layer on top of the other. Below the image, a caption \"Secondary structure -- the repeating pattern in the structure of the peptide chains, such as an α-helix or pleated sheets\" is written in black font.\\n\\nBelow the text, a depiction of a 3D structure of a tangled coil. It is composed of multiple gray loops connected to form a sphere shape. Below the image, a caption \"Tertiary structure -- the three-dimensional folding of the secondary structure.\"\\n\\nBelow the tertiary structure description, a 3D structure of four coils that are joined together. It is composed of multiple gray loops connected to form a sphere shape. The four coils are connected together with dashed red lines. Below the image, a caption \"Quaternary structure -- the three-dimensional arrangement of more than one tertiary polypeptide.\" is written in black font. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-13-20.jpg'}, page_content=\"The image is a diagram illustrating the mechanism of enzyme action. The diagram shows the steps of an enzyme-catalyzed reaction.\\n\\n**1) Substrate binding**:  The substrate, represented by a yellow crescent-shaped molecule, is shown binding to the active site of the enzyme, represented by a light blue circle with a crevice. The active site of the enzyme is labeled.\\n\\n**2) Enzyme-substrate complex formation**: The enzyme and substrate together are now called an enzyme-substrate complex.  This complex is shown as a light blue circle with a yellow crescent-shaped molecule bound within.\\n\\n**3) Product formation**:  The enzyme facilitates the conversion of the substrate to a product. The products are shown as two separate yellow crescent-shaped molecules.\\n\\n**4) Product release**:  The products are released from the enzyme. The enzyme is now free to bind to another substrate molecule.  \\n\\n**5) Enzyme specificity**:  A separate section of the image shows a red molecule that is incompatible with the enzyme's active site. This illustrates that enzymes are specific for their substrates. The text accompanying this red molecule describes this incompatibility and the implications for the enzymatic reaction.\\n\\n**Text labels**:  The image includes text labels to identify the components of the reaction, including: substrate, enzyme, active site, enzyme/substrate complex formed, and products.  Arrows indicate the flow of the reaction and the direction of binding and release.  \\n\\n**Quiz Questions**:  \\n\\n1. What is the name of the part of the enzyme where the substrate binds?\\n2. What is the name given to the enzyme and substrate together?\\n3. What is the product of this reaction?\\n4. What does the red molecule in the image represent?\\n5. Why can't the red molecule bind to the active site of the enzyme? \\n\"),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-13-21.jpg'}, page_content='The image contains a graph with a y-axis labelled \"Rate of reaction\" and an x-axis labelled \"Temperature\".  A blue curve is plotted on this graph. The curve starts low on the y-axis and rises to a peak before declining again. \\n\\nA vertical line is drawn from the peak of the curve to the x-axis. An arrow points to the intersection of this vertical line and the x-axis.  There are three text boxes on the image. One states: \"The rate of reaction increases, doubling with each 10°C rise in temperature.\" A second states: \"Optimum temperature - here the reaction proceeds as fast as possible.\" The third states: \"The enzyme loses its ability to catalyse the reaction.\"  An arrow points down from the first text box to the rising part of the curve.  An arrow points down from the third text box to the declining part of the curve. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-13-22.jpg'}, page_content='The image is a graph with a curved line depicting the relationship between rate of reaction and substrate concentration. \\n\\n* **X-axis:** Substrate concentration, labeled with an arrow pointing to the right\\n* **Y-axis:** Rate of reaction, labeled with an arrow pointing upwards\\n* **Line:** A curved line that starts at the origin and asymptotes at the upper limit of the y-axis, representing the maximum rate of reaction.\\n* **Vmax:** Labeled as \"maximum rate of reaction\" and indicated with a horizontal line at the upper limit of the y-axis. \\n* **Text:** The text below the graph describes the relationship between the rate of reaction and substrate concentration. The text also notes that at lower substrate concentrations, some enzyme molecules have their active sites free, while at higher concentrations, the enzyme becomes saturated and all sites become occupied.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-13-23.jpg'}, page_content=\"The image contains a graph with a blue curve, a black line, and a black triangle. The graph has a grid with thin lines and a thicker x axis and y axis at the bottom left. The y-axis is labeled 'y' and the x-axis is labeled 'x'. The black line forms the hypotenuse of the black right triangle.  The triangle has a right angle at the origin. The curve begins at the origin and increases as it moves rightwards. The curve approaches a horizontal asymptote at a y value greater than 1.\"),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-24.jpg'}, page_content='The image contains the word \"Glucose\" in bold, black font. Beneath this word, there is a chemical formula: 6 CH2OH. The formula is written in a smaller font size and is grey.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-25.jpg'}, page_content='The image is a structural formula of glucose. It depicts a six-membered ring structure. The ring is made up of five carbon atoms and one oxygen atom. The carbon atoms are numbered 1-5, and the oxygen atom is not numbered. The ring is connected to six other atoms: four hydrogen atoms, one hydroxyl group (OH), and one CH2OH group. Each carbon atom is connected to four other atoms. The  hydroxyl groups are attached to the 2nd, 3rd, and 6th carbon atoms. The CH2OH group is attached to the 5th carbon atom. There is a hydrogen atom attached to the 1st carbon atom. The image is labelled \"Glucose\". The label is written in bold and is at the top of the image.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-26.jpg'}, page_content='The image contains two diagrams, one labelled \"Glucose\" and the other labelled \"Amylopectin\".\\n\\n**Glucose**\\nThe diagram depicts a ring of 6 carbon atoms labelled from 1 to 6,  with a hydrogen atom attached to each carbon atom. There are additional hydrogen atoms and hydroxyl groups (OH) attached to carbon atoms 1, 2, 3, and 4. The carbon atoms are numbered 1 to 6, and the other atoms (H and O) are numbered 1 to 6 as well. The 6-carbon ring is a representation of the glucose molecule, and the numbers 1 to 6 correspond to the positions of the carbon atoms in the molecule.\\n\\n**Amylopectin**\\nThe diagram depicts a chain of 6-carbon rings, with a hydrogen atom attached to each carbon atom. The 6-carbon ring has 1-4 glycosidic bonds between rings.  There is another branch of 6-carbon rings that joins the main chain through a 1-6 glycosidic bond. There is a note indicating 1, 6 glycosidic bond and 1, 4 glycosidic bond. The 6-carbon rings are connected by oxygen atoms, which are represented by circles. Each 6-carbon ring has a hydrogen atom attached to each of its six carbon atoms. The rings are connected by oxygen atoms, which are represented by circles. The chain is branched, with a smaller chain of 6-carbon rings branching off the main chain. The smaller chain is connected to the main chain through a 1, 6 glycosidic bond, indicated by a note on the diagram. The main chain of 6-carbon rings are connected by 1, 4 glycosidic bonds.  There are additional hydrogen atoms and hydroxyl groups (OH) attached to some of the carbon atoms. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-27.jpg'}, page_content='The image contains the word \"Amylopectin\" in bold black font. It is written in all capital letters. The word is centered on a white background.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-28.jpg'}, page_content='The image is a structural diagram of amylopectin, a type of starch.  The molecule is composed of repeating units of glucose connected by glycosidic bonds. The main chain of the molecule is linked by 1,4 glycosidic bonds, while branch points are formed by 1,6 glycosidic bonds.  The branch points are indicated by the text \"1,6 glycosidic bond\" and the main chain is indicated by the text \"1,4 glycosidic bond\". Each repeating unit is a hexagonal ring containing one oxygen atom and five carbon atoms, and each carbon atom is connected to either a hydrogen atom or an OH group.  The molecule is depicted as a series of interconnected rings.  The branching pattern of amylopectin gives it a highly branched structure.  The molecule is labeled with the word \"Amylopectin\" at the top. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-29.jpg'}, page_content='The image contains the word \"Maltose\" in black, bold font.  The word is centered horizontally. There are no other components in the image.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-30.jpg'}, page_content='The image contains the word \"Sucrose\" written in bold, black font. Below the word is the chemical formula \"H2OH\".  There is no other content in the image.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-31.jpg'}, page_content='The image depicts the chemical structure of the sugar Sucrose. The structure consists of two six-membered rings. Each ring consists of five carbons and one oxygen. Each carbon atom is bonded to one or more hydrogen atoms. The rings are linked by a single oxygen atom. There are four hydroxyl groups (OH) attached to the rings. The rings are labeled with the chemical formula CH2OH on the top right and top left sides.  A large bolded title \"Sucrose\" is displayed above the chemical structure. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-32.jpg'}, page_content='The image shows the chemical structure of maltose and sucrose. \\n\\nMaltose is composed of two glucose molecules linked by a 1,4-glycosidic bond. Each glucose molecule has six carbon atoms numbered 1 to 6. The carbon atoms are connected to hydrogen atoms, hydroxyl groups (OH), and oxygen atoms (O). \\n\\nSucrose is composed of one glucose molecule and one fructose molecule linked by a glycosidic bond. The glucose molecule has six carbon atoms numbered 1 to 6, while the fructose molecule has six carbon atoms numbered 1 to 6. The carbon atoms are connected to hydrogen atoms, hydroxyl groups (OH), and oxygen atoms (O).'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-33.jpg'}, page_content='The image shows the structure of maltose, a disaccharide. Two six-membered rings connected by a glycosidic bond. Each ring has numbers 1-6 associated with each corner of the ring. The glycosidic bond is labeled and described as \"1,4 glycosidic bond\".  The word \"maltose\" is written below the structure.  \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-34.jpg'}, page_content='The image contains the word \"Fructose\" in bold, black font.  The word is centered on the image with white background. There is also a small circle located below the word.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-35.jpg'}, page_content='The image is of a chemical structure diagram of the sugar fructose. The image consists of 6 carbon atoms, numbered 1 through 6. Each carbon is bonded to hydrogen (H) and/or oxygen (O) atoms. Each carbon atom is labelled with a number indicating it\\'s position in the molecule. There are three hydroxyl groups (-OH) and one ether group (-O-). There is a single bond between each carbon atom. The molecule is labeled \"Fructose\".  This image would be useful for teaching students about the structure of fructose.  The image could also be used to generate quiz questions such as: What is the chemical formula for fructose? How many carbon atoms are in a fructose molecule? What are the functional groups present in a fructose molecule?'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-36.jpg'}, page_content='The image contains the word \"Amylose\" written in black, bold, sans-serif font. The word is centered on a white background. The word is written in all capital letters.  The letters are all the same size and are evenly spaced. The word \"Amylose\" is a type of starch.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-37.jpg'}, page_content='The image shows the chemical structures of Amylose and Fructose.\\n\\n* **Amylose** is a linear chain of glucose monomers joined by alpha-1,4-glycosidic bonds. The chain is represented by a series of six-membered rings connected by oxygen atoms. The repeating unit consists of a six-membered ring with an oxygen atom at the top, two CH2 groups at the bottom, and a single CHOH group at the top.\\n\\n* **Fructose** is a six-carbon monosaccharide with a five-membered ring. The ring is represented by a pentagon with an oxygen atom at the top. The ring has four CHOH groups, one at the top and three on the sides. There is also a CH2OH group attached to the ring at the bottom. There are numerical labels for the carbon atoms in the ring.\\n\\nThe image also includes the text \"side group\" above the Amylose structure. This likely refers to the CHOH group that is not part of the repeating unit. The text \"Amylose\" is in bold and appears at the top of the image. The text \"Fructose\" is in bold and appears at the top of the image.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-14-38.jpg'}, page_content='The image shows a chemical structure. It consists of six interconnected pyranose rings. Each ring has one oxygen atom and five carbon atoms. The carbon atoms are represented by the intersection points of the lines. Each intersection point has two lines protruding. Two of these lines connect to adjacent carbon atoms in the ring. The remaining two lines are the chemical bonds connecting the ring to its adjacent rings.  The ring at the left of the image has an additional bond extending from one carbon. It is labeled \"side group\". \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-16-39.jpg'}, page_content='The image contains a line graph with a blue line plotted on a grid with a black background. The y-axis is labelled with numbers from 0 to 80 with increments of 10. The x-axis is labelled with numbers from 0 to 10 with increments of 1. The line starts at (0,0) and increases linearly for the first 3 units of the x-axis. The rate of increase then decreases between x values of 3 and 4, then remains constant at approximately 75 until x = 10. The line is increasing and concave down.  The graph is plotted on a grid, with every minor grid line incrementing by 1 unit. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-17-40.jpg'}, page_content='The image is of a white grid with thin grey lines. The lines are evenly spaced and form a regular pattern of squares. There are no other elements in the image.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-17-41.jpg'}, page_content='The image is a grid of 24 rows and 30 columns.  The grid lines are thin and gray.  The background of the image is white. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-17-42.jpg'}, page_content='The image contains a grid of small, equally spaced squares. The grid is composed of thin, gray lines that extend across the entire image. There is a faint, horizontal line that appears to be thicker than the rest. It might be a darker line, a shadow, or simply an optical illusion caused by the regularity of the grid. The grid is white in colour, and the lines are a very light gray colour.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-19-43.jpg'}, page_content='The image is a diagram of the human heart. The diagram shows the chambers of the heart, the valves, and the major blood vessels that connect to the heart. The heart is shown in cross-section, with the left ventricle on the left side of the image and the right ventricle on the right side.  The atria are shown above the ventricles.\\n\\nThe following are the components of the image and their characteristics:\\n\\n* **Heart**: The heart is shown as a cross-section of a 3-dimensional object. It is coloured pink, light blue and yellow.  It has a rounded shape with a pointed apex.\\n* **Blood vessels**: The blood vessels are represented by lines with arrows indicating the direction of blood flow. There are two types of lines: red lines with red arrows, and blue lines with blue arrows. \\n* **Labels**: The labels identify different parts of the heart and blood vessels. They are written in black and white.\\n* **Key**: The key is located in the top right corner of the image and explains the colours used to differentiate between the oxygenated and deoxygenated blood. The key includes a red arrow with the label \"flow of oxygenated blood\" and a blue arrow with the label \"flow of deoxygenated blood\".\\n\\nThe image depicts the path of blood flow through the heart, with red representing oxygenated blood and blue representing deoxygenated blood.  \\n\\n**Quiz Questions:**\\n\\n* What are the two main chambers of the heart?\\n* What is the function of the valves in the heart?\\n* What is the difference between oxygenated and deoxygenated blood?\\n* What is the name of the vessel that carries blood away from the heart to the lungs?\\n* What is the name of the vessel that carries blood back to the heart from the lungs?\\n* What is the name of the muscle that separates the left and right ventricles?\\n* What is the function of the papillary muscle?\\n* What is the name of the pointed tip of the heart?'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-19-44.jpg'}, page_content='The image contains two diagrams of a heart in two stages of the heart beat.  \\n\\n* **Top Diagram** is labelled \"Diastole - the heart is relaxed and fills with blood.\" This image shows the heart in a relaxed state with blood flowing into the right and left ventricles from the atria through open atrioventricular valves, labelled \"atrioventricular valves open\".  The semilunar valves are labelled \"semilunar valves closed\" and are closed, indicating the heart is not ejecting blood. \\n* **Bottom Diagram** is labelled \"Systole - the heart (atria followed by ventricles) contracts and forces blood out to the lungs and around the body.\"  This image shows the heart in a contracted state with blood flowing from the ventricles through open semilunar valves, labelled \"semilunar valves open\", to the lungs and the body.  The atrioventricular valves are labelled \"atrioventricular valves closed\" and are closed, indicating that blood is not flowing from the atria to the ventricles. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-19-45.jpg'}, page_content='The image is a diagram describing gas exchange in the alveoli of the lungs. The diagram shows a blue, cloud-shaped structure that is labeled \"alveolus\". The alveolus is surrounded by a pink structure labeled \"blood capillary\". The alveolus has a high concentration of oxygen (O2) and the blood capillary has a low concentration of O2. The oxygen diffuses from the alveolus into the blood, and carbon dioxide (CO2) diffuses from the blood into the alveolus. The direction of blood flow is indicated by red arrows.  The top part of the image illustrates the structure of the alveolus, which is folded to form a large surface area, and the capillary, which is thin and permeable. The bottom part of the image depicts a zoomed in view of the alveolus and capillary, illustrating how oxygen and carbon dioxide diffuse across the thin membrane between the two structures. \\nThe image also includes the following labels: \"thin endothelial cell of capillary,\" \"squamous epithelial cell of alveolus,\" \"liquid surfactant,\" \"alveolar sac,\" \"a short diffusion distance speeds up the rate of diffusion,\" and \"the low concentration of O2 in the blood is maintained, as blood carries the oxygen away from the alveolar sac.\" \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-2-1.jpg'}, page_content='The image is a scatter plot graph with a line of best fit. The x-axis has values from 0 to 500 and the y-axis has values from 0 to 4000. There are multiple data points plotted on the graph, which are represented by asterisks. The line of best fit is a straight line that runs diagonally across the graph from the bottom left corner to the top right corner.  There are 23 data points on the graph, most concentrated around the origin. One outlier is plotted at x=300 and y=600, and another outlier is plotted at x=500 and y=3600. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-2-2.jpg'}, page_content='The image contains a scatter plot with a linear trendline. There are 20 asterisks scattered across the plot and one solid black line that is slightly angled upward. There are numbers along the x and y axes but no labels for the axes. The x-axis ranges from 0 to 325 and the y-axis ranges from 0 to 12,500. There is a cluster of points near the origin of the graph.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-2-6.jpg'}, page_content='The image is a pie chart that represents the cell cycle. There are 5 sections in the pie chart: G1, S, G2, Mitosis, and Cytokinesis. The sections are labelled accordingly. The pie chart is enclosed in two concentric circles. The outer circle is blue and has an arrow pointing clockwise, and the inner circle is red with an arrow pointing counterclockwise.  The sections are arranged in a clockwise direction, and the text on the left of the chart indicates the order in which the events take place. The pie chart is also labelled with \"cell cycle\", \"interphase\", and \"cytokinesis\" written above and below the pie chart.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-2-7.jpg'}, page_content='Image A:  A circle with a pink outline and a purple center. Inside the purple center are tangled lines.   There are two smaller circles inside the center one. The outer circle is labeled \"nuclear membrane\" and  the inner circle is labeled \"nucleolus\".  Between the two smaller circles are lines labeled \"chromatin threads (DNA already replicated)\".  \\n\\nImage B:  A circle with a purple outline and a red center.   There are two X-shaped structures with black lines that cross in the middle.  The lines are labeled \"chromosomes showing two chromatids\".  Inside the circle to the left, there is a line that is labeled \"nuclear membrane\".  Inside the circle to the right, there is a line that is labeled \"nucleolus disappears\".  \\n\\nImage C:  A circle with a blue outline and a red center. There are two red X-shaped structures with black lines that cross in the middle. The lines are labeled \"chromosomes attached to spindle fibre by centromere\".   There is a black line labeled \"centriole\" that is coming from the left side of the center.  The top and bottom of the circle are labeled \"pole\" and \"pole\".  There is a line labeled \"equator\"  that goes across the top.  \\n\\nImage D: A circle with a blue outline and a red center.  There are two red X-shaped structures with black lines that cross in the middle. The lines are labeled \"sister chromatids pulled toward opposite poles\". There is a black line labeled \"centriole\" that is coming from the left side of the center.  \\n\\nImage E:   Two circles side by side with purple outlines and red centers.  Each circle has multiple red lines with black lines that cross in the middle. The lines are labeled \"chromosome about to unwind\".  There is a black line labeled \"centriole\" that is coming from the left side of the center.   \\n\\nImage F:   A paragraph with no image. The paragraph contains a description of the late telophase stage of cell division.  It describes the chromosomes becoming decondensed, the reformation of the nuclear membrane and nucleoli, the division of the cytoplasm and the formation of two identical daughter cells.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-20-46.jpg'}, page_content='The image depicts a schematic of the circulatory system. Two different colors represent the different types of blood: Deoxygenated blood is represented by light blue, and oxygenated blood is represented by pink. The circulatory system diagram is arranged in a shape that represents the heart, with blue blood on the left and pink blood on the right. \\n\\n- Deoxygenated blood flows from the veins returning to the heart to the heart. \\n- The heart pumps the blood to the lungs through the pulmonary artery where it is oxygenated.\\n- Oxygenated blood flows from the pulmonary vein carrying blood back to the heart to the heart, then to the aorta, the major artery leaving the heart. \\n- The aorta carries oxygenated blood to the body.\\n- Blood returns to the heart through the veins, and the cycle repeats.\\n\\nThe image features several arrows, pointing in the direction of blood flow. There are also labels that explain different parts of the system:\\n- The lungs are represented as two lobes.\\n- The heart is represented as four chambers. \\n- There are two capillary beds in tissue, indicated by the presence of parallel lines in an oval shape. \\n- \"Pulmonary circulation\" is labelled at the top of the left side of the diagram.\\n- \"Systemic circulation\" is labelled at the right side of the diagram.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-20-47.jpg'}, page_content='The image is a cross-section of an artery. The artery is shown as a circle with a smaller, light blue circle inside. The light blue circle represents the lumen. The circle representing the artery has a thick, yellow layer surrounding the lumen. Surrounding the yellow layer, there is a thin, dark line. The external layer of tough tissue is labeled above the circle representing the artery. The smooth lining of the artery is labeled below the artery, and the description for the middle layers of the artery wall is labeled above and to the right of the artery.  The lumen is labeled below the artery with a description of it being small when the artery is unstretched by the flow of blood from the heart. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-20-48.jpg'}, page_content='The image shows a cross-section of a tube, with the following components:\\n\\n* **Lumen:** A large, oval-shaped space in the center of the tube, colored light blue. \\n* **Inner layer:** A thin, smooth layer surrounding the lumen, colored light yellow. Text labeling this layer reads \"smooth inner surface\".\\n* **Middle layer:** A slightly thicker layer with a dotted appearance, colored yellow. Text labeling this layer reads \"relatively thin layer of smooth muscle with few elastic fibres\".\\n* **Outer layer:** A thicker layer with a dotted appearance, colored yellow. Text labeling this layer reads \"outer tough layer consisting mainly of collagen fibres\".'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-20-49.jpg'}, page_content='The image shows a pink circle with a yellow outline and blue dots.  The circle is surrounded by an orange ring with small blue dots. The orange ring has a blue arrow pointing out of it labeled \"oxygen and food molecules\" and another blue arrow pointing into it labeled \"waste material eg carbon dioxide\". There is text below the orange ring labeled \"capillary wall (epithelial cells).\"  The blue arrows are curved and indicate the direction of movement.  The blue dots are evenly spaced around the circle and ring.  The pink circle has a smooth outer edge and a smooth inner edge. The yellow outline of the circle is smooth. The orange ring has a smooth outer edge and an inner edge that is segmented and follows the contour of the blue dots.  The yellow outline is filled in with a lighter color.  The blue dots are circular and filled in solid blue.  The arrows are filled with blue and have an arrowhead.  The text is black and the font is sans serif.  The text is positioned above and below the image.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-24-50.jpg'}, page_content='The image depicts a diagram of the heart with blood vessels.  The image shows the left and right side of the heart.  There are three blood vessels on the right side of the image that are attached to the heart.  There is one blood vessel on the left side that is attached to the heart.   The heart is drawn in a simplistic black and white style.  The heart is depicted as an outline of the shape of a human heart.  The blood vessels are drawn as simple tubes.  The text \"Right side\" appears in the lower left corner of the image, and the text \"Left side\" appears in the lower right corner of the image.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-25-51.jpg'}, page_content='The image contains two gray boxes with text and two gray curved arrows connecting them. The upper box contains the text \"Lungs\" in bold and \"Blood vessel B\" in normal text. The lower box contains \"Heart\" in bold. The curved arrow connecting the boxes starts at the bottom of the upper box and points leftward. The second curved arrow connecting the boxes starts at the right side of the bottom box and points leftward. The two arrows are concentric.  \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-25-52.jpg'}, page_content=\"The image shows a blank graph with two axes. The y-axis is labelled 'Blood pressure' with an arrow pointing upwards. The x-axis has five labels, from left to right: 'Heart', 'Blood vessel A', 'Blood vessel B', 'Blood vessel C', and 'Heart'. The x-axis has an arrow pointing rightwards.\"),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-26-53.jpg'}, page_content='The image is a line graph. The x-axis is labeled \"Time / hours\" and ranges from 0 to 5 with increments of 1.  The y-axis is labeled \"Concentration of substance in cytoplasm / µg cm<sup>-3</sup>\" and ranges from 0 to 15 with increments of 5.  There are two lines on the graph.  A black line labeled \"Substance A\" increases linearly from 0 to 15 along the y-axis.  A second black line labeled \"Substance B\" increases slowly from 0 to 5 at approximately 2 hours and remains constant for the remainder of the graph.  The background of the graph is a gray grid.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-3-3.jpg'}, page_content='The image is a scatter plot. The x-axis has a range of 0 to 500. The y-axis has a range of -10,000 to 10,000.  There are 20 data points plotted on the graph. The data points are black squares. The background of the graph is a dotted pattern. There is a black line at the origin of the axes. There are black numbers for the y-axis labels, and the axes are labelled with black lines.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-4-10.jpg'}, page_content='The image contains three sections. The left section contains 10 blue circles of the same size. The middle section contains a structure made of 2 rows of 13 orange-brown cylindrical objects, surrounded by 2 rows of light brown, thin, rectangular objects. The right section contains 4 blue circles of the same size.  A black arrow points from the left section to the right section.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-4-11.jpg'}, page_content='The image contains three components: \\n\\n* **Left:**  A collection of five blue circles, randomly scattered, representing a set of molecules. \\n* **Center:**  A black arrow pointing to the right. \\n* **Right:**  A group of nine blue circles, also randomly scattered, representing a set of molecules. \\n* **Middle:**  A vertical representation of a membrane, with an orange exterior and a green interior. There are multiple vertically oriented columns with orange circles on the sides. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-4-8.jpg'}, page_content='The image shows two beakers.  The beaker on the left contains a group of pink spheres at the bottom and a large number of smaller blue circles throughout the beaker. The beaker on the right contains the same number of blue circles and pink spheres, but the pink spheres are spread out throughout the beaker.  A black arrow points from the left beaker to the right beaker.  The image is labeled with text explaining that the pink spheres are potassium manganate(VII) ions and the blue circles are water molecules. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-4-9.jpg'}, page_content='The image shows a diagram illustrating facilitated diffusion. It is divided into three parts, each showing a cell membrane with protein channels inside of it. The cell membrane is depicted as two parallel rows of orange ovals that have yellow inside. The protein channel is depicted as a purple shape. In the first part of the image,  blue circles representing molecules are located outside the cell membrane, and there is an arrow pointing down indicating their movement from a high concentration to a low concentration.  In the second part, the molecules are moving inside the protein channel, and an arrow is pointing down to show the movement. The protein channel is shown as a purple shape with a black arrow in the middle indicating its shape change.  In the third part, the blue circles are located inside the cell membrane and an arrow pointing down indicates movement.  The first part also has a blue box with the text \"high concentration of molecules\" above it and \"low concentration of molecules\" below it. The first part also has a blue box with the text \"high concentration of molecules\" above it and \"low concentration of molecules\" below it. The third part contains a text box that reads: \"Facilitated diffusion acts as a ferry across the lipid membrane seal. But this is a boat with no oars or sails or engine - it can only work when the tide (the concentration gradient) is in the right direction.\"  The second part also has a box that reads \"The protein carrier changes shape and the molecules are passed into the cell.\"'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-7-12.jpg'}, page_content='The image shows a diagram of a bacterial cell.  There is a long, thin,  orange structure on the left side of the image. This is labelled  \"photosynthetic membranes*\". This structure connects to a larger rectangular structure, labelled \"cell surface membrane\" at its top right corner.  Inside the cell, there are several components labelled:  \"mesosome*\", \"small ribosomes\", \"glycogen granules, lipid droplets\", and \"A\", \"B\", and \"C\". The glycogen granules and lipid droplets are in the top left corner, the ribosomes in the top right corner, and the mesosome in the middle left, there are several other structures in the interior of the cell, including some circular shapes that are labelled  \"A\" and \"B\", and another structure labelled \"C\".  The interior of the cell has a light purple colour. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-7-13.jpg'}, page_content='The image is a table with two columns. The first column has the header \"Animal Cell Feature\" and the second column has the header \"Function\". The table is empty.'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-8-14.jpg'}, page_content='The image is a microscopic view of a cell undergoing mitosis.\\n\\nA - shows a cell with chromosomes lined up in the center.\\nB - shows a cell with chromosomes condensed and paired, and a thin line present in the middle.\\nC - shows a cell with chromosomes at opposite ends of the cell.\\nD - shows a cell with a single nucleus and chromosomes no longer visible. \\n'),\n",
       " Document(metadata={'image_url': '/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images/figure-8-15.jpg'}, page_content='The image contains a simple schematic of a cell. The cell has an irregular shape with a purple circle in the middle labelled as the \"nucleus\". The rest of the cell is light blue with the label \"cytoplasm\"  at the bottom right.  The outline of the cell is labelled as \"cell surface membrane\" with a line pointing to the boundary of the cell. The cell has a  solid, purple nucleus and a  solid blue  cytoplasm. The cell surface membrane  is drawn with a solid purple line. \\n')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genenerate_image_summaries(\"/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/projects AI/kai-ai-backend/app/features/quizzify/images\n"
     ]
    }
   ],
   "source": [
    "dir = (os.path.dirname(os.path.abspath(\"./images\")))\n",
    "\n",
    "absolute_file_path = os.path.join(dir, \"images\")\n",
    "print(absolute_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "\n",
    "# Attempt to remove the directory and all its contents\n",
    "try:\n",
    "    shutil.rmtree(\"./images\")  # Deletes the directory and all files/subdirectories inside it\n",
    "except OSError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath(__file__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
